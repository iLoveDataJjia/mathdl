\documentclass[11pt,en]{elegantpaper}

% Docs
\title{MathDNN - A deep mathematical understanding of DNNs}
\author{James JIANG \\ Data Engineer / Scientist \\ France \and Alex JIANG \\ Preparatory class for the Grandes Écoles \\ France}
\institute{\href{https://github.com/iLoveDataJjia}{iLoveDataJjia Github}}

\version{0.00}
\date{\today}

% Packages
\usepackage{array}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{fourier}
\usepackage{accents}
\usepackage[short]{optidef}

\newtheorem{convention}{Convention}
\newtheorem{notation}{Notation}
\newtheorem{assumption}{Assumption}

% Custom commands
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\Real}{\mathbb{R}}

% Start build
\begin{document}

\maketitle

\begin{abstract}
  Frameworks such as \href{https://www.tensorflow.org/?hl=en}{TensorFlow} or \href{https://pytorch.org/}{PyTorch} make deep learning developments
  easy. They have made this field wide spread for every enthusiast. Implementations only needs an instinctive understanding of deep learning.
  The proper math aspect is little by little forgotten. Topology, Normalized vector space, Limit plus continuity, Taylor series expansion,
  Riemann integral theory, Matrix, Finite dimensional linear algebra and Linear application matrix theories are supposed known. The objective
  is to do a collection of the important propositions explaining dense neural network (DNN) theories. All the propositions will be
  mathematically proven as far as possible and under assumptions if necessary. The subject used as reference is a multi-class classification
  problem with – dense layers, activation layers, Categorical cross-entropy loss and Stochastic gradient descent optimizer with momentum.
  But all the elements below can be easily re-used or re-defined to cover regressions.
  \keywords{Dense neural network, Differentiability, Continuous optimization}
\end{abstract}

\section{Fundamentals}

\subsection{Matrices}

% Set not empty
\begin{convention}
  All sets considered are not empty.
\end{convention}

% Matrix notation
\begin{notation}
  Let $a_{i,j} \in \Real$ for $i \in \llbracket 1,n \rrbracket$ and $j \in \llbracket 1,m \rrbracket$.
  Then a real matrix of dimension $n * m$ will noted as \begin{equation*}
    A = \begin{bmatrix}
      a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
      a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{n,1} & a_{n,2} & \cdots & a_{n,m}
    \end{bmatrix}
  \end{equation*}

  The following notations are also considered \begin{gather*}
    \forall i \in \llbracket 1,n \rrbracket, \forall j \in \llbracket 1,m \rrbracket, A_{i,j} = a_{i,j} \\
    \forall j \in \llbracket 1,m \rrbracket, A_{:,j} = \begin{bmatrix}
      a_{1,j} \\
      \vdots \\
      a_{n,j}
    \end{bmatrix} \\
    \forall i \in \llbracket 1,n \rrbracket, j \in \llbracket 1,m \rrbracket, A_{i,j} = \begin{bmatrix}
      a_{i,1} & \cdots & a_{i,n}
    \end{bmatrix}
  \end{gather*}

  The notation $\mathcal{M}_{n,m}$ means the matrix set of dimension $n \times m$ with coefficients in $\Real$. \par
  The notation $\mathcal{M}_{n,m}(E)$ means the matrix set of dimension $n \times m$ with coefficients in $E \subseteq \Real$.
\end{notation}

% Vector convention to matrix row
\begin{convention}
  Let $E \subseteq \Real$. \par
  A vector is a matrix with only one row. Thus, the vector set $E^n$ is equivalent to $\mathcal{M}_{1,n}(E)$. \par
  A $m$-tuple of vectors is a matrix with $m$ rows. Thus, the cartesian products of vectors $(E^n)^m$ is equivalent to $\mathcal{M}_{m,n}(E)$.
\end{convention}

% Matrix product
\begin{notation}
  Let $A \in \mathcal{M}_{n,m}$ and $B \in \mathcal{M}_{m,p}$. Let the product noted $A * B$ be \begin{gather*}
    C = A * B
  \end{gather*} \par
  where $C \in \mathcal{M}_{n,p}$ with \begin{gather*}
    \forall i \in \llbracket 1,n \rrbracket, \forall j \in \llbracket 1,p \rrbracket, C_{i,j} = \sum_{k=1}^n A_{i,k} * B_{k,j}
  \end{gather*}

\end{notation}

% Matrix transpose
\begin{notation}
  The matrix transpose operation will be noted as $A^T$.
\end{notation}

% Matrix identity
\begin{notation}
  The notation $I_n$ means the identity matrix of size $n \times n$. \begin{equation*}
    I_n = \begin{bmatrix}
      1 & 0 & \cdots & 0 \\
      0 & 1 & \ddots & \vdots \\
      \vdots & \ddots & \ddots & 0 \\
      0 & \cdots & 0 & 1
    \end{bmatrix}
  \end{equation*}
\end{notation}

% Norm
\begin{notation}
  Let $a \in \Real^n$. The eucliean norm on $\Real^n$ will be noted as $\norm a _n$.
  \begin{gather*}
    \norm a _n = \sqrt{a * a^T}
  \end{gather*}
\end{notation}

\subsection{Differential calculus}

% Base notations
\begin{notation}
  Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $a \in \Real^n$ and $r \in \Real^+*$. \par
  The notation $\mathring{E}$ means the interior of $E$. \par
  The notation $f : E \longrightarrow F$ means the application from $E$ to $F$. \par
  The notation $\mathcal{F}(E,F)$ means the set of applications from $E$ to $F$. \par
  The notation $\mathcal{C}(E,F)$ means the set of continuous applications from $E$ to $F$. \par
  The notation $\mathcal{L}(E,F)$ means the set of linear applications from $E$ to $F$. \par
  The notation $\mathcal{B}(a,r)$ means the set $\{x \in \Real^n | \norm{x - a}_n \leq r\}$.
\end{notation}

% Differentiable definition
\begin{definition}
  Let $E \subseteq \Real^n$ and $F \subseteq \Real^m$.
  Then $f$ \textit{differentiable} on $E$ means \begin{equation}\label{def:differentiable}
    \begin{gathered}
      \forall a \in \mathring{E}, \exists \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m), \\
      \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta),
        f(a+h) = f(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)
    \end{gathered}
  \end{equation}

  $\frac{\partial f}{\partial \cdot}(a)$ is named differential of $f$ on $a$. \par
  The notation $\mathcal{D}(E,F)$ means the set of \textit{differentiable} applications from $E$ to $F$.
\end{definition}

% Differentiable properties
\begin{proposition}\label{prop:differential_unique}
  {\normalfont Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $f \in \mathcal{D}(E,F)$ and $a \in \mathring{E}$.
  Then $\frac{\partial f}{\partial \cdot}(a)$ is unique and $\mathcal{D}(E,F) \subset \mathcal{C}(E,F)$.}
\end{proposition}

\begin{proof}
  Suppose $\phi_1$ and $\phi_2$ two differentials of $f$ on $a$. \begin{equation*}
    \begin{gathered}
      \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta), \phi_2(h) - \phi_1(h) \underset{(\ref{def:differentiable})} = \underset{h \to 0}o(\norm h _n)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      & \underset{def} \implies \forall \epsilon \in \Real^{+*}, \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta), \norm{\phi_2(h) - \phi_1(h)}_m \leq 2 * \norm h _n * \epsilon \\
      & \underset{\phi_2 - \phi_1 \in \mathcal{L}(\Real^n,\Real^m)} \implies \forall \epsilon \in \Real^{+*}, \forall h \in \Real^n, \norm{\phi_2(h) - \phi_1(h)}_m \leq 2 * \norm h _n * \epsilon \\
      & \underset{\epsilon \to 0} \implies \forall h \in \Real^n, \phi_2(h) = \phi_1(h)
    \end{split}
  \end{equation*}
  
  Let $f \in \mathcal{D}(E,F).$ and $a \in \mathring{E}$. \begin{equation*}
    \begin{split}
      \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m) & \implies \frac{\partial f}{\partial \cdot}(a) \in \mathcal{C}(\Real^n,\Real^m), \frac{\partial f}{\partial 0_{\Real^n}}(a) = 0_{\Real^m} \\
      & \underset{(\ref{def:differentiable})} \implies f(a + h) \underset{h \to 0} \to f(a)
    \end{split}
  \end{equation*}
\end{proof}

% Jacobian definition
\begin{definition}
  Let $E \subseteq \Real^n$, $F \subseteq \Real^m$ and $f = (f_1 \ldots f_m) \in \mathcal{D}(E,F)$.
  Then $f_i$ is \textit{differentiable} on $E$ for all $i \in \llbracket 1,m \rrbracket$. The jacobian is defined as \begin{equation}
    \begin{array}{llll}
      \mathcal{J}_f & : & \mathring{E} & \longrightarrow \mathcal{M}_{m,n} \\
        &   & a & \longmapsto \begin{bmatrix}
        \frac{\partial f}{\partial e_1}(a) & \cdots & \frac{\partial f}{\partial e_n}(a)
      \end{bmatrix} = \begin{bmatrix}
        \frac{\partial f_1}{\partial e_1}(a) & \cdots & \frac{\partial f_1}{\partial e_n}(a) \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f_m}{\partial e_1}(a) & \cdots & \frac{\partial f_m}{\partial e_n}(a) \\
      \end{bmatrix}
    \end{array}
  \end{equation}

  $(e_i)_{i \in \llbracket 1,n \rrbracket}$ means the matrices $e_i = \begin{bmatrix}
    0 & \cdots & \underset{\text{at column $i$}} 1 & \cdots & 0
  \end{bmatrix}$ corresponding to $\Real^n$ standard basis. \par
  $\frac{\partial f}{\partial e_i}$ is named the partial derivative of $f$ according the $i^{th}$ variable. \par
  The jacobian is also named gradient when $m=1$ and is noted as $\nabla_f = \mathcal{J}_f$. \par
  The jacobian is also named derivative when $m=1$ with $n=1$ and is noted as $f' = \nabla_f = \mathcal{J}_f$.
\end{definition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $a \in \mathring{E}$.
  \begin{equation*}
    \begin{gathered}
      \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta),
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      f_i (a + h) & = f(a + h)_i \\
      & = f(a)_i + \frac{\partial f}{\partial h}(a)_i + \underset{h \to 0}o(\norm h _n)_i \\
      & = f_i(a) + \frac{\partial f}{\partial h}(a)_i + \underset{h \to 0}o(\norm h _n)_i
    \end{array}
  \end{equation*}
  \begin{equation*}
    \frac{\partial f}{\partial \cdot}(a)_i \in \mathcal{L}(\Real^n,\Real) \underset{prop\ref{prop:differential_unique}}\implies \frac{\partial f_i}{\partial \cdot}(a) = \frac{\partial f}{\partial \cdot}(a)_i
  \end{equation*}
\end{proof}

% Jacobian definition corollary
\begin{corollary}
  {\normalfont Let $E \subseteq \Real^n$, $F \subseteq \Real^m$ and $f \in \mathcal{D}(E,F)$.
  The jacobian of $f$ on $a \in \mathring{E}$ fixed is the canonical associated matrix to the differential of $f$ on $a$.} \par
  \normalfont{\textbf{Notes:} It means a function differentiability can also be proved by exhibing its jacobian.} \par
\end{corollary}

\begin{proof}
  Let $a \in \mathring{E}$.
  $\frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m)$ and any linear application in finite dimension
  with values in $\Real$ has an unique associated matrix in the standard basis called canonical associated matrix. \par
\end{proof}

% Jacobian of two applications sum
\begin{proposition}\label{prop:jacobians_sum}
  {\normalfont
    Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $f \in \mathcal{D}(E,F)$ and $g \in \mathcal{D}(E,F)$.
    Then $g + f \in \mathcal{D}(E,F)$ and \begin{equation}
      \begin{array}{llll}
        \mathcal{J}_{g + f} & : & \mathring{E} & \longrightarrow F \\
        &   & a & \longmapsto \mathcal{J}_{g}(a) + \mathcal{J}_{f}(a)
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $a \in \mathring{E}$.
  \begin{equation*}
    \begin{gathered}
      \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta),
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      (g + f)(a+h) & = g(a+h) + f(a+h) \\
      & \underset{(\ref{def:differentiable})}{=} g(a) + f(a) + \frac{\partial g}{\partial h}(a) + \frac{\partial f}{\partial h}(a) + 2 * \underset{h \to 0}o(\norm h _n) \\
      & = (g + f)(a) + \frac{\partial g}{\partial h}(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)
    \end{split}
  \end{equation*}

  \begin{equation*}
    \begin{split}
      \frac{\partial g}{\partial \cdot}(a) + \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n, \Real^m)
      & \underset{prop\ref{prop:differential_unique}}\implies g + f \in \mathcal{D}(E,F), \frac{\partial (g + f)}{\partial \cdot}(a) = \frac{\partial g}{\partial \cdot}(a) + \frac{\partial f}{\partial \cdot}(a) \\
      & \underset{mat}\implies \mathcal{J}_{g + f}(a) = \mathcal{J}_{g}(a) + \mathcal{J}_{f}(a)
    \end{split}
  \end{equation*} \par

  \textbf{Note:} $mat$ indicates in canonical associated matrix way. \par
\end{proof}

% Function composition notation
\begin{notation}
  Let $f \in \mathcal{F}(E,F)$ and $g \in \mathcal{F}(F,G)$.
  Then the notation $g \circ f$ means the application \begin{equation*}
    \begin{array}{llll}
      g \circ f & : & E & \longrightarrow G \\
        &   & x & \longmapsto g(f(x))
    \end{array}
  \end{equation*} \par

  Let $f_i \in \mathcal{F}(E_i,E_{i+1})$ for $i \in \llbracket 1,n \rrbracket$.
  Then the notation $\underset{i=1}{\overset{n}\circ} f_i$ means the application \begin{equation*}
    \begin{array}{llll}
      \underset{i=1}{\overset{n}\circ} f_i & : & E_1 & \longrightarrow E_{n+1} \\
        &   & x & \longmapsto f_n( \ldots f_2(f_1(x)))
    \end{array}
  \end{equation*}
\end{notation}

% Chain rule
\begin{theorem}\label{theo:chain_rule}
  {\normalfont
    Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $G \subseteq \Real^p$, $f \in \mathcal{D}(E,F)$ and $g \in \mathcal{D}(F,G)$.
    Then $g \circ f \in \mathcal{D}(E,G)$ and \begin{equation}\label{theo:chain_rule_eq}
      \begin{array}{llll}
        \mathcal{J}_{g \circ f} & : & \mathring{E} & \longrightarrow G \\
        &   & a & \longmapsto \mathcal{J}_{g}(f(a)) * \mathcal{J}_{f}(a)
      \end{array}
    \end{equation} \par
    \textbf{Note:} This theorem is named the chain rule.
  }
\end{theorem}

\begin{proof}
  Let $a \in \mathring{E}$.
  \begin{equation*}
    \begin{gathered}
      \exists \eta \in \Real^{+*}, \forall h \in \mathcal{B}(0_{\Real^n},\eta),
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      (g \circ f)(a+h) & = g(f(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)) \\
      & = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n))}(f(a))
        + \underset{h \to 0}o(\norm{\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)}_n) \\
      & \underset{\frac{\partial f}{\partial \cdot}(a) \in \mathcal{C}(\Real^n,\Real^m),\frac{\partial f}{\partial 0_{\Real^n}}(a) = 0_{\Real^m}}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n))}(f(a)) + \underset{h \to 0}o(\norm h _n) \\
      & \underset{\frac{\partial g}{\partial \cdot}(a) \in \mathcal{L}(\Real^m,\Real^p)}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a))}(f(a)) + \frac{\partial g}{\partial (\underset{h \to 0}o(\norm h _n))}(f(a)) + \underset{h \to 0}o(\norm h _n) \\
      & \underset{\frac{\partial g}{\partial \cdot}(a) \in \mathcal{C}(\Real^m,\Real^p),\frac{\partial g}{\partial 0_{\Real^m}}(a) = 0_{\Real^p}}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a))}(f(a)) + \underset{h \to 0}o(\norm h _n)
    \end{split}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      \frac{\partial g}{\partial (\frac{\partial f}{\partial \cdot}(a))}(f(a)) = \frac{\partial g}{\partial \cdot}(f(a)) \circ \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n, \Real^p)
      & \underset{prop\ref{prop:differential_unique}}\implies g \circ f \in \mathcal{D}(E,G), \frac{\partial (g \circ f)}{\partial \cdot}(a) = \frac{\partial g}{\partial \cdot}(f(a)) \circ \frac{\partial f}{\partial \cdot}(a) \\
      & \underset{mat}\implies \mathcal{J}_{g \circ f}(a) = \mathcal{J}_{g}(f(a)) * \mathcal{J}_{f}(a)
    \end{split}
  \end{equation*}
\end{proof}

\subsection{Others}

% Cartesian products
\begin{notation}
  Let $E$ and $F$ two sets and $(E_i)_{i \in \llbracket 1,n \rrbracket}$ $n$ sets. \par
  The notation $E \times F$ means the cartesian product between $E$ and $F$. \par
  The notation $\underset{i=1}{\overset{n}\circ} E_i$ means the cartesian product $E_n \times \ldots \times E_1$.
\end{notation}

% Kronecker delta
\begin{notation}
  The notation $\delta_{\cdot,\cdot}$ means the kronecker delta application \begin{equation*}
    \begin{array}{llll}
      \delta_{\cdot,\cdot} & : & \mathbb{Z} \times \mathbb{Z} & \longrightarrow \{0,1\} \\
      &   & (i,j) & \longmapsto \begin{array}{ll}
        1 & i = j \\
        0 & i \neq j
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Indicator function
\begin{notation}
  Let $E \subseteq \Real^n$. The notation $\mathbb{1}_E$ means the indicator function of $E$ on $\Real^n$.
  \begin{equation*}
    \begin{array}{llll}
      \mathbb{1}_E & : & E & \longrightarrow \{0,1\}^n \\
      &   & x & \longmapsto \begin{array}{ll}
        1 & x \in E \\
        0 & x \notin E
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Max function
\begin{notation}
  The notation $max(0,\cdot)$ means the application
  \begin{equation*}
    \begin{array}{llll}
      max(0,\cdot) & : & \Real & \longrightarrow \Real^+ \\
      &   & x & \longmapsto \begin{array}{ll}
        x & x > 0 \\
        0 & x \leq 0
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Max differential assumption
\begin{assumption}\label{assump:max_differentiable}
  $max(0,\cdot) \in \mathcal{D}(\Real, \Real^+)$ with
  \begin{equation*}
    \begin{array}{lllll}
      max(0,\cdot)' & : & \Real & \longrightarrow \Real^+ \\
      &   & x & \longmapsto \mathbb{1}_{\Real^{+*}}(x)
    \end{array}
  \end{equation*}\par

  \textbf{Note:} $max(0,\cdot)$ is actually not \textit{differentiable} on $0$ and the notation $\Real^{*}$ means $\Real_{\backslash\{0\}}$. \par
\end{assumption}

% Fixed variable function
\begin{notation}
  Let $f$ an application with $n$ inputs and $m$ outputs.
  \begin{equation*}
    \begin{array}{llll}
      f & : & E_1 \times \ldots \times E_n & \longrightarrow F_1 \times \ldots \times F_m \\
      &   & (x_1, \ldots, x_n) & \longmapsto f(x_1, \ldots, x_n)
    \end{array}
  \end{equation*} \par

  Let $k \in \llbracket 1,n \rrbracket$. The notation $f(x_1, \ldots, x_{k-1}, \cdot, x_{k+1}, \ldots, x_n)$ means \begin{equation*}
    \begin{array}{llll}
      f(x_1, \ldots, x_{k-1}, \cdot, x_{k+1}, \ldots, x_n) & : & E_k & \longrightarrow F_1 \times \ldots \times F_m \\
      &   & x_k & \longmapsto f(x_1, \ldots, x_{k-1}, x_k, x_{k+1}, \ldots, x_n)
    \end{array}
  \end{equation*}
\end{notation}

\section{Activation functions}

% Act function notation
\begin{notation}
  Let $E \subseteq \Real^m \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{act}(E,F)$ means the set of activation functions from $E$ to $F$. \par
  \textbf{Note:} An activation function is an application defined in this section. \par
\end{notation}

% ReLU definition
\begin{definition}
  Let the activation function \textit{ReLU} noted as $\mathcal{R}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathcal{R} & : & \Real^m & \longrightarrow \Real^m \\
      &   & z & \longmapsto \begin{bmatrix}
        max(0,z_1) \\
        \vdots \\
        max(0,z_m)
      \end{bmatrix}
    \end{array}
  \end{equation*} \par
\end{definition}

% ReLU differential
\begin{proposition}
  {\normalfont
    $\mathcal{R} = (\mathcal{R}_1 \ldots \mathcal{R}_m) \in \mathcal{D}(\Real^m,\Real^m)$ and its jacobian is \begin{equation}\label{prop:relu_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathcal{R}} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & z & \longmapsto \begin{bmatrix}
          \mathbb{1}_{\Real^{+*}}(z_1) & 0 & \cdots & 0 \\
          0 & \mathbb{1}_{\Real^{+*}}(z_2) & \ddots & \vdots \\
          \vdots & \ddots & \ddots & 0 \\
          0 & \cdots & 0 & \mathbb{1}_{\Real^{+*}}(z_m) \\
        \end{bmatrix}
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$.
  \begin{equation*}
    \begin{split}
      \mathcal{R}_i(z) = max(0,z_i) & \underset{assump\ref{assump:max_differentiable}}\implies \frac{\partial \mathcal{R}_i}{\partial e_j}(z)
        = \begin{array}{ll}
          \mathbb{1}_{\Real^{+*}}(z_i) & i = j \\
          0 & i \neq j
      \end{array}
    \end{split}
  \end{equation*}
\end{proof}

% Softmax definition
\begin{definition}
  Let the activation function \textit{Softmax} noted as $\mathcal{S}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathcal{S} & : & \Real^m & \longrightarrow ]0,1[^m \\
      &   & z & \longmapsto \begin{bmatrix}
        \frac{e^{z_1}}{\sum_{k=1}^m e^{z_k}} \\
        \vdots \\
        \frac{e^{z_m}}{\sum_{k=1}^m e^{z_k}}
      \end{bmatrix}
    \end{array}
  \end{equation*} \par
\end{definition}

% Softmax differential
\begin{proposition}
  {\normalfont
    $\mathcal{S} = (\mathcal{S}_1 \ldots \mathcal{S}_m) \in \mathcal{D}(\Real^m,]0,1[^m)$ and its jacobian is \begin{equation}\label{prop:softmax_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathcal{S}} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & z & \longmapsto \begin{bmatrix}
          \mathcal{S}_1 * (1 - \mathcal{S}_1) & - \mathcal{S}_1 * \mathcal{S}_2 & \cdots & - \mathcal{S}_1 * \mathcal{S}_m \\
          - \mathcal{S}_2 * \mathcal{S}_1 & \mathcal{S}_2 * (1 - \mathcal{S}_2) & \ddots & \vdots \\
          \vdots & \ddots & \ddots & - \mathcal{S}_{m-1} * \mathcal{S}_m \\
          - \mathcal{S}_m * \mathcal{S}_1 & \cdots & - \mathcal{S}_m * \mathcal{S}_{m-1} & \mathcal{S}_m * (1 - \mathcal{S}_m) \\
        \end{bmatrix} (z)
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \mathcal{S}_i(z) = \frac{e^{z_i}}{\sum_{k=1}^m e^{z_k}}
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{lll}
      & \implies \frac{\partial \mathcal{S}_i}{\partial e_j} (z) & = \frac{(\delta_{i,j} * e^{z_i}) * {\sum_{k=1}^m e^{z_k}} - e^{z_j} * e^{z_i}}{(\sum_{k=1}^m e^{z_k})^2} \\
      & & = \delta_{i,j} * \mathcal{S}_i(z) - \mathcal{S}_j(z) * \mathcal{S}_i(z) \\
      & & = \mathcal{S}_i(z) * (\delta_{i,j} - \mathcal{S}_j(z))
    \end{array}
  \end{equation*}
\end{proof}

\section{Loss}

% Loss function notation
\begin{notation}
  Let $E \subseteq \Real^m \times \Real^m$, $F \subseteq \Real$. \par
  The notation $\mathcal{F}_{loss}(E,F)$ means the set of loss functions from $E$ to $F$. \par
  \textbf{Note:} A loss function is an application defined in this section. \par
\end{notation}

% Categorical cross-entropy loss definition
\begin{definition}
  Let the loss function \textit{Categorical cross-entropy} noted as $\xi$ be
  \begin{equation*}
    \begin{array}{llll}
      \xi & : & ]0,1[^m \times \{0,1\}^m & \longrightarrow \Real \\
      &   & (y,y^*) & \longmapsto - \sum_{k=1}^m y_k^* * \log(y_k)
    \end{array}
  \end{equation*} \par
\end{definition}

% Categorical cross-entropy loss differential
\begin{proposition}
  {\normalfont
    Let $y^* \in \{0,1\}^m$. $\xi(\cdot,y^*) \in \mathcal{D}(]0,1[^m, \Real)$ and its gradient is \begin{equation}\label{prop:cce_differential}
      \begin{array}{llll}
        \nabla_{\xi(\cdot,y^*)} & : & ]0,1[^m  & \longrightarrow \Real \\
        &   & y & \longmapsto - \begin{bmatrix}
          \frac{y^*_1}{y_1} & \ldots & \frac{y^*_m}{y_m}
        \end{bmatrix}
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $y \in ]0,1[^m$. \begin{equation*}
    \begin{array}{lll}
      \xi(y,y^*) = - \sum_{k=1}^m y_k^* * \log(y_k) & \implies \frac{\partial \xi(\cdot,y^*)}{\partial e_j} (y) & = - \frac{y_j^*}{y_j}
    \end{array}
  \end{equation*}
\end{proof}

\section{Layers}

% Layers notation
\begin{notation}
  Let $E \subseteq \Real^n \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{layer}(E,F)$ means the set of layer functions from $E$ to $F$. \par
  \textbf{Note:} A layer function is an application defined in this section. \par
\end{notation}

% Dense layer definition
\begin{definition}
  Let the layer function \textit{Dense layer} noted as $\mathbb{L}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathbb{L} & : & \Real^n \times \mathcal{M}_{m,n} \times \Real^m & \longrightarrow \Real^m \\
      &   & (y,W,b) & \longmapsto y * W^T + b
    \end{array}
  \end{equation*} \par
  \textbf{Note:} $\mathbb{L} : \Real^n \times \mathcal{M}_{m,n} \times \Real^m \longrightarrow \Real^m$
  is equivalent to $\mathbb{L} : \Real^n \times (\Real^n)^{m} \times \Real^m \longrightarrow \Real^m$.
\end{definition}

% Dense layer differential on y
\begin{proposition}
  {\normalfont
    Let $W \in \mathcal{M}_{m,n}$ and $b \in \Real^m$.
    $\mathbb{L}(\cdot,W,b) = (\mathbb{L}_1(\cdot,W,b) \ldots \mathbb{L}_m(\cdot,W,b)) \in \mathcal{D}(\Real^n, \Real^m)$
    and its gradient is \begin{equation}\label{prop:densel_y_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(\cdot,W,b)} & : & \Real^n  & \longrightarrow \mathcal{M}_{m,n} \\
        &   & y & \longmapsto W
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$
  and $y \in \Real^n$. \begin{equation*}
    \begin{array}{lll}
      \mathbb{L}(y,W,b) = y * W^T + b & \implies \mathbb{L}_i(y,W,b) & = y * W_{i,:}^T + b_i \\
      & \implies \frac{\partial \mathbb{L}_i(\cdot,W,b)}{\partial e_j} (y) & = W_{i,j}
    \end{array}
  \end{equation*}
\end{proof}

% Dense layer differential on W
\begin{proposition}
  {\normalfont
    Let $y \in \Real^n$, $(w^{(k)})_{k \in \llbracket 1,m-1 \rrbracket} \in (\Real^n)^{m-1}$, $b \in \Real^m$. \par
    $\forall i^* \in \llbracket 1,m \rrbracket,$
    $\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\underset{\text{at index $i^*$}}{\cdot},w^{(i^*)},\ldots,w^{(m-1)},b) \in \mathcal{D}(\Real^n, \Real^m)$
    and jacobians are \begin{equation*}
      \begin{gathered}
        \forall i^* \in \llbracket 1,m \rrbracket,
      \end{gathered}
    \end{equation*}
    \begin{equation}\label{prop:densel_W_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)} & : & \Real^n  & \longrightarrow \mathcal{M}^{m,n} \\
        &   & w & \longmapsto \begin{bmatrix}
          & (0) & \\
          y_1 & \cdots & y_n \\
          & (0) &
        \end{bmatrix} \text{\small{at row $i^*$}}
      \end{array}
    \end{equation} \par
    \textbf{Note:} For $i^*=1$ and $i^*=m$,
    the applications $\mathbb{L}(y,\cdot,w^{(1)},\ldots,w^{(m-1)},b)$ and $\mathbb{L}(y,w^{(1)},\ldots,w^{(m-1)},\cdot,b)$ are meant respectively.
  }
\end{proposition}

\begin{proof}
  Let $i^* \in \llbracket 1,m \rrbracket$, $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$ and $w \in \Real^n$. \begin{equation*}
    \begin{gathered}
      \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)(w) \\
      = \begin{bmatrix}
        y * {w^{(1)}}^T &
        \cdots &
        y * {w^{(i^*-1)}}^T &
        y * w^T &
        y * {w^{(i^*)}}^T &
        \cdots &
        y * {w^{(m-1)}}^T
      \end{bmatrix} + b
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{gathered}
      \implies \frac{\partial \mathbb{L}_i(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}{\partial e_j} (w) = \begin{array}{ll}
        y_j & i = i^* \\
        0 & i \neq i^*
      \end{array}
    \end{gathered}
  \end{equation*}
\end{proof}

% Dense layer differential on b
\begin{proposition}
  {\normalfont
    Let $y \in \Real^n$ and $W \in \mathcal{M}_{m,n}$.
    $\mathbb{L}(y,W,\cdot) = (\mathbb{L}_1(y,W,\cdot) \ldots \mathbb{L}_m(y,W,\cdot)) \in \mathcal{D}(\Real^m, \Real^m)$
    and its gradient is \begin{equation}\label{prop:densel_b_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(y,W,\cdot)} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & b & \longmapsto I_m
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$
  and $b \in \Real^m$. \begin{equation*}
    \begin{array}{lll}
      \mathbb{L}(y,W,b) = y * W^T + b & \implies \mathbb{L}_i(y,W,b) & = y * W_{i,:}^T + b_i \\
      & \implies \frac{\partial \mathbb{L}_i(y,W,\cdot)}{\partial e_j} (b) & = \delta_{i,j}
    \end{array}
  \end{equation*}
\end{proof}

\section{Neural network}

\subsection{Simplified jacobian matrices}

% F^upstream circ ReLU differential
\begin{proposition}
  {\normalfont
    Let $\mathcal{F}^{(upstream)} \in \mathcal{D}(\Real^m,\Real)$ and
    $\mathcal{R} \in \mathcal{F}_{act}(\Real^m,\Real^m)$.
    $\mathcal{F}^{(upstream)} \circ \mathcal{R} \in \mathcal{D}(\Real^m,\Real)$ and its gradient is \begin{equation} \label{prop:relu_simplified_differential}
      \begin{array}{llll}
        \nabla_{\mathcal{F}^{(upstream)} \circ \mathcal{R}} & : & \Real^m  & \longrightarrow \Real^m \\
        &   & z & \longmapsto \begin{bmatrix}
          \nabla_{\mathcal{F}^{(upstream)}}(y)_1 * \mathbb{1}_{\Real^{+*}}(z_1) & \cdots &
            \nabla_{\mathcal{F}^{(upstream)}}(y)_m * \mathbb{1}_{\Real^{+*}}(z_m)
        \end{bmatrix}
      \end{array}
    \end{equation} \par
    where \begin{equation*}
      y = \mathcal{R}(z)
    \end{equation*}

    \textbf{Note:} It means such a gradient can be implemented without matrix multiplication.
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$.
  \begin{equation*}
    \begin{split}
      \nabla_{\mathcal{F}^{(upstream)} \circ \mathcal{R}} \underset{(\ref{theo:chain_rule_eq})}{=}
        \nabla_{\mathcal{F}^{(upstream)}}(\mathcal{R}(z)) * \mathcal{J}_{\mathcal{R}}(z) &
      \underset{(\ref{prop:relu_differential})}\implies \frac{\partial \mathcal{F}^{(upstream)} \circ \mathcal{R}}{\partial e_j}(z)
        = \nabla_{\mathcal{F}^{(upstream)}}(\mathcal{R}(z))_j * \mathbb{1}_{\Real^{+*}}(z_j)
    \end{split}
  \end{equation*}
\end{proof}

% F^upstream circ Dense layer differential on W
\begin{proposition}
  {\normalfont
    Let $\mathcal{F}^{(upstream)} \in \mathcal{D}(\Real^m,\Real)$,
      $\mathbb{L} \in \mathcal{F}_{layer}(\Real^n \times (\Real^n)^m \times \Real^m,\Real^m)$,
      $y \in \Real^n$, $(w^{(k)})_{k \in \llbracket 1,m-1 \rrbracket} \in (\Real^n)^{m-1}$ and $b \in \Real^m$. \par
    $\forall i^* \in \llbracket 1,m \rrbracket,$
    $\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\underset{\text{at index $i^*$}}{\cdot},w^{(i^*)},\ldots,w^{(m-1)},b) \in \mathcal{D}(\Real^n, \Real)$
    and gradients are \begin{equation*}
      \begin{gathered}
        \forall i^* \in \llbracket 1,m \rrbracket,
      \end{gathered}
    \end{equation*}
    \begin{equation} \label{prop:densel_W_simplified_differential}
      \begin{array}{llll}
        \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)} & : & \Real^n  & \longrightarrow \Real^n \\
        &  & w & \longmapsto \nabla_{\mathcal{F}^{(upstream)}}(z)_{i^*} * y
      \end{array}
    \end{equation} \par
    where \begin{equation*}
      z = \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},w,w^{(i^*)},\ldots,w^{(m-1)},b)
    \end{equation*}

    \textbf{Note:} It means these gradients for $i^* \in \llbracket 1,m \rrbracket$ can be implemented with $\nabla_{\mathcal{F}^{(upstream)}}(z)^T * y$.
  }
\end{proposition}

\begin{proof}
  Let $i^* \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$ and $w \in \Real^n$.
  Let $z = \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},w,w^{(i^*)},\ldots,w^{(m-1)},b)$. \begin{equation*}
    \begin{gathered}
      \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}(w)
        \underset{(\ref{theo:chain_rule_eq})}{=} \nabla_{\mathcal{F}^{(upstream)}}(z) *
        \mathcal{J}_{\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}(w)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{gathered}
      \underset{(\ref{prop:densel_W_differential})}{\implies}
        \frac{\partial \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}}{\partial e_j} (w)
        = \nabla_{\mathcal{F}^{(upstream)}}(z)_{i^*} * y_j
    \end{gathered}
  \end{equation*}
\end{proof}

% Categorical cross-entropy loss composed with Softmax differential
\begin{proposition}
  {\normalfont
    Let $\mathcal{S} \in \mathcal{F}_{act}(\Real^m,]0,1[^m)$ and $\xi \in \mathcal{F}_{loss}(]0,1[^m \times \{0,1\}^m, \Real)$. \par
    Let $y^* \in \{0,1\}^m$ with $\norm{y^*}_m = 1$.
    $\xi(\cdot,y^*) \circ \mathcal{S} \in \mathcal{D}(\Real^m,\Real)$ and its gradient is \begin{equation}\label{prop:cce_softmax_differential}
      \begin{array}{llll}
        \nabla_{\xi(\cdot,y^*) \circ \mathcal{S}} & : & \Real^m  & \longrightarrow \Real \\
        &   & z & \longmapsto \mathcal{S}(z) - y^*
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \nabla_{\xi(\cdot,y^*) \circ \mathcal{S}}(z) \underset{(\ref{theo:chain_rule_eq})}{=} \nabla_{\xi(\cdot,y^*)}(\mathcal{S}(z)) * \mathcal{J}_{\mathcal{S}}(z)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{lll}
      & \implies \frac{\partial \xi(\cdot,y^*) \circ \mathcal{S}}{\partial e_j} (z)
        & \underset{(\ref{prop:softmax_differential}),(\ref{prop:cce_differential})}= - y_j^* + \sum_{k=1}^m {y_k^* * \mathcal{S}_j(z)} \\
      & & \underset{y^* \in \{0,1\}^m, \norm{y}_m = 1}{=} \mathcal{S}_j(z) - y_j^*
    \end{array}
  \end{equation*}
\end{proof}

\subsection{Definitions}

% Neural network notation
\begin{notation}
  Let $E \subseteq \Real^n \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{net}(E,F)$ means the set of neural network functions from $E$ to $F$. \par
  \textbf{Note:} A neural network is an application defined in this section. \par
\end{notation}

% Multi-Class DNN definition
\begin{definition}
  Let $(m_k)_{k \in \llbracket 0,p \rrbracket} \in (\mathbb{N}^*)^p$. Let the neural network
  \textit{Multi-class dense neural network} noted as $\mathcal{N}_{c^+}$ be \begin{equation*}
    \begin{array}{llll}
      \mathcal{N}_{c^+} & : & \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ) & \longrightarrow \Real^{m_p} \\
      &   & (x,(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket}) & \longmapsto
      ( \mathcal{S} \circ \mathbb{L}^{(p)}(\cdot, W^{(p)}, b^{(p)}) ) \circ ( \underset{k=1}{\overset{p-1}{\circ}} \mathcal{R}^{(k)} \circ \mathbb{L}^{(k)}(\cdot, W^{(k)}, b^{(k)}) ) (x)
    \end{array}
  \end{equation*} \par

  where \begin{equation*}
    \begin{array}{ll}
      & (\mathbb{L}^{(k)})_{k \in \llbracket 1,p \rrbracket} \in
        \underset{k=1}{\overset{p}{\times}} \mathcal{F}_{layer}(\Real^{m_{k-1}} \times \mathcal{M}_{m_{k},m_{k-1}} \times \Real^{m_{k}}, \Real^{m_{k}}) \\
      & (\mathcal{R}^{(k)})_{k \in \llbracket 1,p-1 \rrbracket} \in
        \underset{k=1}{\overset{p-1}{\times}} \mathcal{F}_{act}(\Real^{m_k}, \Real^{m_k}) \\
      & \mathcal{S} \in \mathcal{F}_{act}(\Real^{m_p}, ]0,1[^{m_p})
    \end{array}
  \end{equation*}
  
  \textbf{Note:} $\mathcal{N}_{c^+} : \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )
    \longrightarrow \Real^{m_p}$
  is equivalent to $\mathcal{N}_{c^+} : \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )
  \longrightarrow \Real^{m_p}$.
\end{definition}

% Multi-Class DNN properties
\begin{corollary}
  \normalfont{
    $\mathcal{N}_{c^+} \in \mathcal{D}(\Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real^{m_p})$
    and the total number of parameter is \begin{equation*}
      \sum_{k=1}^{p} m_{k} * (m_{k-1} + 1)
    \end{equation*}
  }
\end{corollary}

\begin{proof}
  $\mathcal{N}_{c^+}$ is a composition of \textit{differentiable} applications so it is \textit{differentiable} by the \hyperref[theo:chain_rule]{chain rule} theorem.
  Let $a \in ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )$
  then $a$ has $\sum_{k=1}^{p} m_{k} * m_{k-1} + \sum_{k=1}^{p} m_{k}$ coefficients. \par
\end{proof}

% Multi-Class DNN objective function
\begin{definition}
  Let $(m_k)_{k \in \llbracket 0,p \rrbracket}$, $\mathcal{N}_{c^+} \in
    \mathcal{F}_{net}(\Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real^{m_p})$,
    $X = (x^{(i)})_{i \in \llbracket 1,n \rrbracket} \in (\Real^{m_0})^n$
    and $Y^* = ({y^*}^{(i)})_{i \in \llbracket 1,n \rrbracket} \in (\{0,1\}^{m_p})^n$ with $\forall i \in \llbracket 1,n \rrbracket$, $\norm{{y^*}^{(i)}}_{m_p} = 1$. \par
  Let the \textit{Multi-class optimization problem} noted as $(\mathcal{P}_{c^+})$ be \begin{mini}
    {(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket}}
    {\sum_{i=1}^{n}{\xi(y^{(i)},{y^*}^{(i)})}}
    {}{(\mathcal{P}_{c^+})\text{ : }}
  \end{mini} \par
  where \begin{equation*}
    \begin{array}{ll}
      & \xi \in \mathcal{F}_{loss}(]0,1[^{m_p} \times \{0,1\}^{m_p}, \Real) \\
      & y^{(i)} = \mathcal{N}_{c^+}(x^{(i)},(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket})
    \end{array}
  \end{equation*} \par

  $\sum_{i=1}^{n} \xi (\cdot, {y^*}^{(i)}) \circ \mathcal{N}_{c^+}(x^{(i)},\cdot,\cdot)$ is named the objective function
  and will be noted as $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$.
\end{definition}

% Multi-Class DNN objective function differentiability
\begin{corollary}
  {\normalfont
    $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot) \in \mathcal{D}((\underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real)$. \par
    \textbf{Note:} Its gradients for each variable can be computed recursively through each composition using
    $(\ref{prop:jacobians_sum})$, $(\ref{theo:chain_rule_eq})$,
    $(\ref{prop:densel_y_differential})$, $(\ref{prop:densel_W_simplified_differential})$, $(\ref{prop:densel_b_differential})$,
    $(\ref{prop:relu_simplified_differential})$ and $(\ref{prop:cce_softmax_differential})$.
  }
\end{corollary}

\begin{proof}
  $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$ is a sum and composition of \textit{differentiable} applications so it is \textit{differentiable} by the proposition $\ref{prop:jacobians_sum}$ and \hyperref[theo:chain_rule]{chain rule} theorem. \par
\end{proof}

% Gradient descent
\section{Gradient descent}

\subsection{Optimization fundamentals}

% Applicaton convex
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$. $f$ \textit{convex} means \begin{equation}\label{def:convex_eq}
    \begin{gathered}
      \forall x \in \Real^m, \forall y \in \Real^m, \\
      \forall \tau \in [0,1], f(\tau * x + (1 - \tau) * y) \leq \tau * f(x) + (1 - \tau) * f(y)
    \end{gathered}
  \end{equation}
\end{definition}

% Application convex equivalent with gradient
\begin{proposition}
  {\normalfont
    Let $f \in \mathcal{D}(\Real^m,\Real)$. $f$ \textit{convex} is equivalent to \begin{equation}\label{prop:convex_grad}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        f(x) + \nabla_f(x) * (y - x)^T \leq f(y)
      \end{gathered}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Suppose $f$ \textit{convex} $(\ref{def:convex_eq})$. Let $x \in \Real^m$ and $y \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \exists \eta \in \Real^{+*}, \forall \tau \in [-\eta,\eta], \\
      f(x + \tau * (y - x)) \underset{\norm{\cdot}_m \in \mathcal{C}(\Real^m,\Real),(\ref{def:differentiable})}{=}
        f(x) + \frac{\partial f}{\partial (\tau * (y - x))}(x) + \underset{\tau \to 0}o(\norm{\tau * (y - x)}_m)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      & \underset{(\ref{def:convex_eq})}{\implies}
        \begin{gathered}
          \exists \eta \in \Real^{+*}, \forall \tau \in [-\eta,\eta], \\
          f(x) + \frac{\partial f}{\partial (\tau * (y - x))}(x) + \underset{\tau \to 0}o(\norm{\tau * (y - x)}_m)
          \leq \tau * f(y) + (1 - \tau) * f(x)
        \end{gathered} \\
      & \underset{\frac{\partial f}{\partial \cdot} \in \mathcal{L}(\Real^m,\Real)}{\implies}
        \exists \eta \in \Real^{+*}, \forall \tau \in [-\eta,\eta],
        \frac{\partial f}{\partial (y - x)}(x) + \underset{\tau \to 0}o(\norm{y - x}_m)
        \leq f(y) - f(x) \\
      & \underset{\tau \to 0}{\implies}
        \frac{\partial f}{\partial (y - x)}(x) \leq f(y) - f(x) \\
      & \underset{mat}{\implies}
        f(x) + \nabla_f(x) * (y - x)^T \leq f(y)
    \end{array}
  \end{equation*} \par \par

  Suppose $(\ref{prop:convex_grad})$. Let $x \in \Real^m$, $y \in \Real^m$ and $\tau \in [0,1]$. Let $z = \tau * x + (1 - \tau) * y$.
  \begin{equation*}
    \begin{array}{lll}
      (a) : & f(z) - (1 - \tau) * \nabla_f(z) * (y - x)^T & \underset{(\ref{prop:convex_grad})}{=} f(z) + \nabla_f(z) * (x - z)^T \leq f(x) \\
      (b) : & f(y) + \tau * \nabla_f(z) * (y - x)^T & \underset{(\ref{prop:convex_grad})}{=} f(z) + \nabla_f(z) * (y - z)^T \leq f(y)
    \end{array}
  \end{equation*}
  \begin{equation*}
    \underset{\tau * (a) + (1 - \tau) * (b)}{\implies} f(z) \leq \tau * f(x) + (1 - \tau) f(y)
  \end{equation*}
\end{proof}

% L-smooth definition
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$ and $L \in \Real^{+*}$. $f$ \textit{L-smooth} means \begin{equation}\label{def:lsmooth_eq}
    \begin{gathered}
      \forall x \in \Real^m, \forall y \in \Real^m, \\
      \norm{\nabla_f(x) - \nabla_f(y)}_m \leq L * \norm{x - y}_m 
    \end{gathered}
  \end{equation}
\end{definition}

% L-smooth proposition
\begin{proposition}
  {\normalfont
    Let $f \in \mathcal{D}(\Real^m,\Real)$ and $L \in \Real^{+*}$. If $f$ \textit{L-smooth} then \begin{equation}\label{prop:lsmooth_implies}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        f(y) \leq f(x) + \nabla_f(x) * (y - x)^T + \frac{L}{2} * \norm{y - x}_m^2
      \end{gathered}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $x \in \Real^m$ and $y \in \Real^m$. Let \begin{equation*}
    \begin{array}{llll}
      g & : & [0,1] & \longrightarrow \Real^m \\
      & & \tau & \longmapsto x + \tau * (y - x)
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      \forall \tau \in [0,1], (f \circ g)(\tau) = f(x + \tau * (y - x)) & \underset{(\ref{theo:chain_rule_eq})}{\implies}
        \forall \tau \in [0,1], (f \circ g)'(\tau) = \nabla_f(g(\tau)) * (y - x)^T \\
      & \underset{\int_{}^{}}{\implies} f(y) - f(x) = \int_{0}^{1}{\nabla_f(g(\tau)) * (y - x)^T d\tau}
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      f(y) & = f(x) + \int_{0}^{1}{\nabla_f(g(\tau)) * (y - x)^T d\tau} \\
      & = f(x) + \nabla_f(x) * (y - x)^T + \int_{0}^{1}{(\nabla_f(g(\tau)) - \nabla_f(x)) * (y - x)^T d\tau} \\
      & \underset{Cauchy-Schwarz}{\leq} f(x) + \nabla_f(x) * (y - x)^T + \int_{0}^{1}{\norm{\nabla_f(g(\tau)) - \nabla_f(x)}_m * \norm{y - x}_m d\tau} \\
      & \underset{(\ref{def:lsmooth_eq})}{\leq} f(x) + \nabla_f(x) * (y - x)^T + L * \norm{y - x}_m^2 * \int_{0}^{1}{\tau d\tau}
    \end{array}
  \end{equation*}
\end{proof}

% Co-coercivity for gradient
\begin{proposition}
  {\normalfont
    Let $L \in \Real^{+*}$ and $f \in \mathcal{D}(\Real^m,\Real)$. If $f$ \textit{convex} and \textit{L-smooth} then \begin{equation}\label{prop:grad_cocoercivity}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        \frac{1}{L} * \norm{\nabla_f(y) - \nabla_f(x)}_m^2 \leq (\nabla_f(y) - \nabla_f(x)) * (y - x)^T
      \end{gathered}
    \end{equation} \par
    \textbf{Notes:} This proposition is named the gradient co-coercivity.
  }
\end{proposition}

\begin{proof}
  Let $x \in \Real^m$, $y \in \Real^m$ and $z = x - \frac{1}{L}(\nabla_f(y) - \nabla_f(x))$.
  \begin{equation*}
    \begin{array}{ll}
      f(y) - f(x) & = f(y) - f(z) + f(z) - f(x) \\
      & \underset{(\ref{prop:convex_grad}),(\ref{prop:lsmooth_implies})}{\leq} \nabla_f(y) * (y - z)^T + \nabla_f(x) * (z - x) + \frac{L}{2} * \norm{z - x}_m^2 \\
      & \leq \nabla_f(y) * (y - x)^T - \frac{1}{2L} * \norm{\nabla_f(x) - \nabla_f(y)}^2_m
    \end{array}
  \end{equation*} \par
  The inequality is true for all $x \in \Real^m$ and $y \in \Real^m$.

  Let $x \in \Real^m$ and $y \in \Real^m$. The previous inequality gives \begin{equation*}
    \begin{array}{lll}
      (a) : & f(y) - f(x) \leq \nabla_f(y) * (y - x)^T - \frac{1}{2L} * \norm{\nabla_f(x) - \nabla_f(y)}^2_m \\
      (b) : & f(x) - f(y) \leq \nabla_f(x) * (x - y)^T - \frac{1}{2L} * \norm{\nabla_f(y) - \nabla_f(x)}^2_m
    \end{array}
  \end{equation*}
  \begin{equation*}
    \underset{(a) + (b)}{\implies} 0 \leq (\nabla_f(y) - \nabla_f(x)) * (y - x)^T - \frac{1}{L} * \norm{\nabla_f(y) - \nabla_f(x)}^2_m
  \end{equation*}
\end{proof}

% Global min definition
\begin{definition}
  Let $f \in \mathcal{F}(\Real^m,\Real)$ and $x^* \in \Real^m$. $a$ \textit{global minimum} of $f$ means \begin{equation}\label{def:glob_min}
    \forall x \in \Real^m, f(x^*) \leq f(x)
  \end{equation}
\end{definition}

% Global min proposition
\begin{proposition}
  {\normalfont
    Let $f \in \mathcal{D}(\Real^m,\Real)$ and $x^* \in \Real^m$. If $x^*$ \textit{global minimum} of $f$ then \begin{equation}\label{prop:glob_min}
      \nabla_f(x^*) = 0_{\Real^m}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $x^*$ \textit{global minimum} of $f$, $v \in \Real^m$ and \begin{equation*}
    \begin{array}{llll}
      g & : & \Real & \longrightarrow \Real^m \\
      & & \tau & \longmapsto x^* + \tau * v
    \end{array}
  \end{equation*}

  \begin{equation*}
    \begin{array}{lll}
      \forall \tau \in \Real, (f \circ g)(\tau) = f(x^* + \tau * v) & \implies & \begin{array}{l}
        (f \circ g)'(0) \underset{(\ref{theo:chain_rule_eq})}{=} \nabla_f(x^*) * v^T \\
        \forall \tau \in \Real, (f \circ g)(0) \underset{(\ref{def:glob_min})}{\leq} (f \circ g)(\tau)
      \end{array}
    \end{array}
  \end{equation*}

  \begin{equation*}
    \begin{gathered}
      \forall \tau \in \Real, (f \circ g)(0) \leq (f \circ g)(\tau) 
      \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      & \underset{(\ref{def:differentiable}),mat}\implies \exists \eta \in \Real^{+*}, \forall \tau \in ]0,\eta], \begin{array}{l}
        0 \leq (f \circ g)'(0) * \tau + \underset{\tau \to 0}{o} (\tau) \\
        0 \leq (f \circ g)'(0) * (- \tau) + \underset{\tau \to 0}{o} (\tau)
      \end{array} \\
      & \implies \exists \eta \in \Real^{+*}, \forall \tau \in ]0,\eta], \underset{\tau \to 0}{o} (\tau) \leq (f \circ g)'(0) \leq \underset{\tau \to 0}{o} (\tau) \\
      & \underset{\tau \to 0}\implies \nabla_f(x^*) * v^T = (f \circ g)'(0) = 0
    \end{array}
  \end{equation*} \par

  The equality is true for all $v \in \Real^m$
  in particular for the vectors $(e_i)_{i \in \llbracket 1,n \rrbracket}$ corresponding to $\Real^m$ standard basis thus \begin{equation*}
    \nabla_f(x^*) = 0_{\Real^m}
  \end{equation*}
\end{proof}

\subsection{Algorithms}

% Gradient descents algorithm notation
\begin{notation}
  The notation $\Real^{\mathbb{N}}$ means the set of numerical sequences. \par
  The notation $\mathcal{G}_{descent}$ means the set of gradient descent sequences. \par
  \textbf{Note:} $\mathcal{G}_{descent} \subset \Real^{\mathbb{N}}$ and a gradient descent sequence is a
  numerical sequence defined in this section.
\end{notation}

% Gradient descent
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$ and $\alpha \in \Real^{+*}$. Let the \textit{Gradient descent}
  be the numerical sequence \begin{equation}\label{def:vanilla_grad_descent}
    (x_v^{(n)})_{n \in \mathbb{N}} = \left\{
      \begin{array}{ll}
        x_v^{(0)} \in \Real^m & n = 0 \\
        x_v^{(n+1)} = x_v^{(n)} - \alpha \nabla_f(x_v^{(n)}) & n \in \mathbb{N}^*
      \end{array}
    \right.
  \end{equation} \par

  $\alpha$ is named the learning rate. \par
  $n \in \mathbb{N}$ fixed is named an epoch.

  \textbf{Note:} For the \textit{Multi-class classification problem} $(\mathcal{P}_{c^+})$,
  $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$ with all parameters fixed but one $W^{(k)}_{i^*,:}$ or $b^{(k)}$ will be $f$
  and $W^{(k)}_{i^*,:}$ or $b^{(k)}$ will be the numerical sequence $(x_v^{(n)})_{n \in \mathbb{N}}$.
  This is only for one parameter $W^{(k)}$ or $b^{(k)}$ but all the parameters are actually optimized simultaneously.
  It means for each iteration $n$ all $W^{(k)}$ or $b^{(k)}$ receive an update.

  \textbf{Note:} The \textit{Stochastic gradient descent} numerical sequence is similar to the \textit{Gradient descent} sequence but instead of
  having $\nabla_f(x_v^{(n)})$ it uses $\nabla_f(x_v^{(n)} | \mathcal{x})$ an estimate of the actual gradient.
  For the \textit{Multi-class classification problem} $(\mathcal{P}_{c^+})$ with $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$, the computations
  can be intensives with large matrices $X$ and $Y^*$. For this reason, several sub-samples (of size $b=32$ generally) of $X$ and $Y^*$ called
  \textit{batches} are used when computing the gradient estimate. More precisely, a \textit{batch} results from a sampling without remplacement
  by couple of rows $X$ and $Y^*$. The last batch can be of size inferior or equal to $b$. $\nabla_f(x_v^{(n)} | \mathcal{x})$
  the estimate is equal to the mean of the gradients of each batch.
\end{definition}

% Gradient descent convergence and rate
\begin{proposition}
  {\normalfont
    Let $\alpha \in \Real^{+*}$, $L \in \Real^{+*}$, $f \in \mathcal{D}(\Real^m,\Real)$ and $(x_v^{(n)})_{n \in \mathbb{N}} \in \mathcal{G}_{descent}$.
    If $f$ \textit{convex}, \textit{L-smooth}, admits $x_v^*$ as a \textit{global minimum} and $\alpha < \frac{2}{L}$ then \begin{equation*}
      \begin{gathered}
        \forall n \in \mathbb{N}^*, f(x_v^{(n)}) - f(x_v^*) \leq \frac{\norm{x_v^{(0)} - x_v^*}^2_m}{nC}
      \end{gathered}
    \end{equation*} \par where \begin{equation*}
      C = \alpha - \frac{L\alpha^2}{2}
    \end{equation*}
  
    \textbf{Note:} It means $(x_v^{(n)})_{n \in \mathbb{N}}$ converge to the global minimum $x_v^*$ with a rate of $\underset{n \to 0}{o}(n^{-1})$.
    In case of $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$, \textit{Stochastic gradient descent} convergence is still an active research subject
    nowadays \citep{gradconv_stochastic:0}.
  }
\end{proposition}

\begin{proof}
  Let $f$ \textit{convex}, \textit{L-smooth}, admits a \textit{global minimum} $x_v^*$ and $\alpha < \frac{2}{L}$ and $n \in \mathbb{N}$.
  \begin{equation*}
    \begin{array}{ll}
      \norm{x_v^{(n+1)} - x_v^*}^2_m  & = \norm{x_v^{(n)} - x_v^* - \alpha {\nabla_f(x_v^{(n)})}}^2_m \\
      & = \norm{x_v^{(n)} - x_v^*}^2_m - 2\alpha (x_v^{(n)} - x_v^*)*{\nabla_f(x_v^{(n)})}^T + \alpha^2 {\norm{\nabla_f(x_v^{(n)})}^2_m} \\
      & \underset{(\ref{prop:grad_cocoercivity})}{\leq} \norm{x_v^{(n)} - x_v^*}^2_m
        - \underbrace{(\frac{2\alpha}{L} - \alpha^2)}_{\in \Real^{+*}} {\norm{\nabla_f(x_v^{(n)})}^2_m} \\
      & \underset{rec}{\leq} \norm{x_v^{(0)} - x_v^*}^2_m
    \end{array}
  \end{equation*} \par
  It also means $(\norm{x_v^{(n)} - x_v^*}_m)_{n \in \mathbb{N}}$ is a \textit{decreasing numerical sequence}. \par
  \textbf{Note:} $rec$ means by applying recursively.

  \begin{equation*}
    \begin{array}{ll}
      f(x_v^{(n+1)}) & \underset{(\ref{def:vanilla_grad_descent}),(\ref{prop:lsmooth_implies})}{\leq} f(x_v^{(n)}) + \nabla_f(x_v^{(n)}) * (-\alpha \nabla_f(x_v^{(n)}))^T + \frac{L}{2} \norm{- \alpha \nabla_f(x_v^{(n)})}_m^2 \\
      & \leq f(x_v^{(n)}) - \underbrace{(\alpha - \frac{L \alpha^2}{2})}_{\in \Real^{+*}} \norm{\nabla_f(x_v^{(n)})}^2
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{llll}
      & \implies & (a) : & 0 \underset{(\ref{def:glob_min})}{\leq} f(x_v^{(n+1)}) - f(x_v^*) \leq f(x_v^{(n)}) - f(x_v^*) - C \norm{\nabla_f(x_v^{(n)})}^2
    \end{array}
  \end{equation*} \par
  Let $\forall n \in \mathbb{N}$, $\delta^{(n)} = f(x_v^{(n)}) - f(x_v^*)$.
  It also means $(\delta^{(n)})_{n \in \mathbb{N}}$ is a \textit{decreasing numerical sequence} with a lower bound of $0$. \par

  If $\forall k \in \llbracket 0,n+1 \rrbracket$, $\delta^{(k)} \neq 0$ and $\norm{x_v^{(0)} - x_v^*}_m \neq 0$ then
  \begin{equation*}
    \begin{array}{ll}
      f(x_v^{(n)}) - f(x_v^*) & \underset{(\ref{prop:convex_grad})}{\leq} \nabla_f(x_v^{(n)}) * (x_v^{(n)} - x_v^*)^T \\
      & \underset{Cauchy-Schwarz}{\leq} \norm{\nabla_f(x_v^{(n)})}_m \norm{x_v^{(n)} - x_v^*}_m \\
      & \leq \norm{\nabla_f(x_v^{(n)})}_m \norm{x_v^{(0)} - x_v^*}_m
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      & \underset{(a)}{\implies} \delta^{(n+1)} \leq \delta^{(n)} - \frac{C}{\norm{x_v^{(0)} - x_v^*}_m^2} * {\delta^{(n)}}^2 \\
      & \implies \frac{C}{\norm{x_v^{(0)} - x_v^*}_m^2}
        \leq \frac{C}{\norm{x_v^{(0)} - x_v^*}_m^2} \frac{\delta^{(n)}}{\delta^{(n+1)}}
        \leq \frac{1}{\delta^{(n+1)}} - \frac{1}{\delta^{(n)}} \\
      & \underset{\sum_{0}^n,tel}\implies \frac{(n+1) C}{\norm{x_v^{(0)} - x_v^*}_m^2}
        \leq \frac{1}{\delta^{(n+1)}} - \frac{1}{\delta^{(0)}}
        \underset{(\ref{def:glob_min})}{\leq} \frac{1}{\delta^{(n+1)}}
    \end{array}
  \end{equation*} \par
  \textbf{Note:} $\sum_{0}^n$ means a sum from $0$ to $n$ and $tel$ means telescopic cancellation. \par

  Else $\exists k \in \llbracket 0,n+1 \rrbracket$, $\delta^{(k)} = 0$ or $\norm{x_v^{(0)} - x_v^*}_m = 0$.
  Let \begin{equation*}
    r = \left\{ \begin{array}{ll}
      \text{min} \{k \in \llbracket 0,n+1 \rrbracket | \delta^{(k)} = 0\} & \norm{x_v^{(0)} - x_v^*}_m \neq 0 \\
      0 & \norm{x_v^{(0)} - x_v^*}_m = 0
    \end{array} \right.
  \end{equation*} \par
  If $r \neq 0$ the exact same reasoning can be done on $\llbracket 0,r-1 \rrbracket$ to obtain the inequality.
  For the rest from $r$ to $n+1$ the inequality is also true because $\forall k \in \llbracket r,n+1 \rrbracket, \delta^{(k)} = 0$ \par
\end{proof}

% Gradient descent with momentum
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$, $\alpha \in \Real^{+*}$ and $\beta \in [0,1]$. Let the \textit{Gradient descent with momentum}
  be the numerical sequence \begin{equation}\label{def:stochastic_grad_descent}
    (x_m^{(n)})_{n \in \mathbb{N}} = \left\{
      \begin{array}{ll}
        x_m^{(0)} \in \Real^m & n = 0 \\
        x_m^{(n+1)} = x_m^{(n)} - \alpha m^{(n)} & n \in \mathbb{N}^*
      \end{array}
    \right.
  \end{equation} \par

  where \begin{equation*}
    (m^{(n)})_{n \in \mathbb{N}} = \left\{
      \begin{array}{ll}
        0_{\Real^m} & n = 0 \\
        m^{(n+1)} = \beta m^{(n)} + (1 - \beta) \nabla_f(x_m^{(n)}) & n \in \mathbb{N}^*
      \end{array}
    \right.
  \end{equation*} \par

  $(m^{(n)})_{n \in \mathbb{N}}$ is named the momentum.

  \textbf{Note:} In case of $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$, an estimate $\nabla_f(x_v^{(n)} | \mathcal{x})$ of the actual gradient
  is mostly used. This defines the \textit{Stochastic gradient descent with momentum} numerical sequence. Its convergence is still an active
  research subject nowadays \citep{gradconv_momentum:1}.
\end{definition}

% Bibliography
\nocite{*}
\bibliography{paper}

\end{document}