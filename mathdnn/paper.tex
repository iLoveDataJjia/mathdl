\documentclass[11pt,en]{elegantpaper}

% Docs
\title{MathDNN - A deep mathematical understanding of DNNs}
\author{James JIANG \\ Data Engineer / Scientist \\ France \and Alex JIANG \\ Preparatory class for the Grandes Écoles \\ France}
\institute{\href{https://github.com/iLoveDataJjia}{iLoveDataJjia Github}}

\version{0.00}
\date{\today}

% Packages
\usepackage{array}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{fourier}
\usepackage{accents}
\usepackage[short]{optidef}

\newtheorem{convention}{Convention}
\newtheorem{notation}{Notation}
\newtheorem{assumption}{Assumption}

% Custom commands
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\Real}{\mathbb{R}}

% Start build
\begin{document}

\maketitle

\begin{abstract}
  Frameworks such as \href{https://www.tensorflow.org/?hl=en}{TensorFlow} or \href{https://pytorch.org/}{PyTorch} make deep learning developments
  easy. They have made this field wide spread for every enthusiast. Implementations only needs an instinctive understanding of deep learning.
  The proper math aspect is little by little forgotten. Topology, Normalized vector space, Limit plus continuity, Taylor series expansion,
  Riemann integral theory, Matrix, Finite dimensional linear algebra and Linear application matrix theories are supposed known. The objective
  is to do a collection of the important propositions explaining dense neural network (DNN) theories. All the propositions will be
  mathematically proven as far as possible and under assumptions if necessary. The subject used as reference is a multi-class classification
  problem with – dense layers, activation layers, Categorical cross-entropy loss and Stochastic gradient descent optimizer with decay and momentum.
  But all the elements below can be easily re-used or re-defined to cover regressions.
  \keywords{Dense neural network, Differentiability, Continuous optimization}
\end{abstract}

\section{Fundamentals}

\subsection{Matrices}

% Set not empty
\begin{convention}
  All sets considered are not empty.
\end{convention}

% Matrix notation
\begin{notation}
  Let $a_{i,j} \in \Real$ for $i \in \llbracket 1,n \rrbracket$ and $j \in \llbracket 1,m \rrbracket$.
  Then a real matrix of dimension $n * m$ will noted as \begin{equation*}
    A = \begin{bmatrix}
      a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
      a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{n,1} & a_{n,2} & \cdots & a_{n,m}
    \end{bmatrix}
  \end{equation*}

  The following notations are also considered \begin{gather*}
    \forall i \in \llbracket 1,n \rrbracket, \forall j \in \llbracket 1,m \rrbracket, A_{i,j} = a_{i,j} \\
    \forall j \in \llbracket 1,m \rrbracket, A_{:,j} = \begin{bmatrix}
      a_{1,j} \\
      \vdots \\
      a_{n,j}
    \end{bmatrix} \\
    \forall i \in \llbracket 1,n \rrbracket, j \in \llbracket 1,m \rrbracket, A_{i,j} = \begin{bmatrix}
      a_{i,1} & \cdots & a_{i,n}
    \end{bmatrix}
  \end{gather*}

  The notation $\mathcal{M}_{n,m}$ means the matrix set of dimension $n \times m$ with coefficients in $\Real$. \par
  The notation $\mathcal{M}_{n,m}(E)$ means the matrix set of dimension $n \times m$ with coefficients in $E \subseteq \Real$.
\end{notation}

% Vector convention to matrix row
\begin{convention}
  Let $E \subseteq \Real$. \par
  A vector is a matrix with only one row. Thus, the vector set $E^n$ is equivalent to $\mathcal{M}_{1,n}(E)$. \par
  A $m$-tuple of vectors is a matrix with $m$ rows. Thus, the cartesian products of vectors $(E^n)^m$ is equivalent to $\mathcal{M}_{m,n}(E)$.
\end{convention}

% Matrix product
\begin{notation}
  Let $A \in \mathcal{M}_{n,m}$ and $B \in \mathcal{M}_{m,p}$. Let the product noted $A * B$ be \begin{gather*}
    C = A * B
  \end{gather*} \par
  where $C \in \mathcal{M}_{n,p}$ with \begin{gather*}
    \forall i \in \llbracket 1,n \rrbracket, \forall j \in \llbracket 1,p \rrbracket, C_{i,j} = \sum_{k=1}^n A_{i,k} * B_{k,j}
  \end{gather*}

\end{notation}

% Matrix transpose
\begin{notation}
  The matrix transpose operation will be noted as $A^T$.
\end{notation}

% Matrix identity
\begin{notation}
  The notation $I_n$ means the identity matrix of size $n \times n$. \begin{equation*}
    I_n = \begin{bmatrix}
      1 & 0 & \cdots & 0 \\
      0 & 1 & \ddots & \vdots \\
      \vdots & \ddots & \ddots & 0 \\
      0 & \cdots & 0 & 1
    \end{bmatrix}
  \end{equation*}
\end{notation}

% Norm
\begin{notation}
  Let $a \in \Real^n$. The eucliean norm on $\Real^n$ will be noted as $\norm a _n$.
  \begin{gather*}
    \norm a _n = \sqrt{a * a^T}
  \end{gather*}
\end{notation}

\subsection{Differential calculus}

% Base notations
\begin{notation}
  Let $E \subseteq \Real^n$ and $F \subseteq \Real^m$. \par
  The notation $\mathring{E}$ means the interior of $E$. \par
  The notation $f : E \longrightarrow F$ means the application from $E$ to $F$. \par
  The notation $\mathcal{F}(E,F)$ means the set of applications from $E$ to $F$. \par
  The notation $\mathcal{C}(E,F)$ means the set of continuous applications from $E$ to $F$. \par
  The notation $\mathcal{L}(E,F)$ means the set of linear applications from $E$ to $F$.
\end{notation}

% Differentiable definition
\begin{definition}
  Let $E \subseteq \Real^n$ and $F \subseteq \Real^m$.
  Then $f$ \textit{differentiable} on $E$ means \begin{equation}\label{def:differentiable}
    \begin{gathered}
      \forall a \in \mathring{E}, \exists \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m), \\
      \forall h \in \Real^n, f(a+h) = f(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)
    \end{gathered}
  \end{equation}

  $\frac{\partial f}{\partial \cdot}(a)$ is named differential of $f$ on $a$. \par
  The notation $\mathcal{D}(E,F)$ means the set of \textit{differentiable} applications from $E$ to $F$.
\end{definition}

% Differentiable properties
\begin{proposition}\label{prop:differential_unique}
  {\normalfont Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $f \in \mathcal{D}(E,F)$ and $a \in \mathring{E}$.
  Then $\frac{\partial f}{\partial \cdot}(a)$ is unique and $\mathcal{D}(E,F) \subset \mathcal{C}(E,F)$.}
\end{proposition}

\begin{proof}
  Suppose $\phi_1$ and $\phi_2$ two differentials of $f$ on $a$. \begin{equation*}
    \begin{gathered}
      \forall h \in \Real^n, \phi_2(h) - \phi_1(h) \underset{(\ref{def:differentiable})} = \underset{h \to 0}o(\norm h _n)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      & \underset{def} \implies \forall \epsilon > 0, \exists \eta > 0, \forall h \in \Real^n, (\norm h _n \leq \eta \Rightarrow \norm{\phi_2(h) - \phi_1(h)}_m \leq 2 * \norm h _n * \epsilon) \\
      & \underset{\phi_2 - \phi_1 \in \mathcal{L}(\Real^n,\Real^m)} \implies \forall \epsilon > 0, \forall h \in \Real^n, \norm{\phi_2(h) - \phi_1(h)}_m \leq 2 * \norm h _n * \epsilon \\
      & \underset{\epsilon \to 0} \implies \forall h \in \Real^n, \phi_2(h) = \phi_1(h)
    \end{split}
  \end{equation*}
  
  Let $f \in \mathcal{D}(E,F).$ and $a \in \mathring{E}$. \begin{equation*}
    \begin{split}
      \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m) & \implies \frac{\partial f}{\partial \cdot}(a) \in \mathcal{C}(\Real^n,\Real^m), \frac{\partial f}{\partial 0_{\Real^n}}(a) = 0_{\Real^m} \\
      & \underset{(\ref{def:differentiable})} \implies f(a + h) \underset{h \to 0} \to f(a)
    \end{split}
  \end{equation*}
\end{proof}

% Jacobian definition
\begin{definition}
  Let $E \subseteq \Real^n$, $F \subseteq \Real^m$ and $f = (f_1 \ldots f_m) \in \mathcal{D}(E,F)$.
  Then $f_i$ is \textit{differentiable} on $E$ for all $i \in \llbracket 1,m \rrbracket$. The jacobian is defined as \begin{equation}
    \begin{array}{llll}
      \mathcal{J}_f & : & \mathring{E} & \longrightarrow \mathcal{M}_{m,n} \\
        &   & a & \longmapsto \begin{bmatrix}
        \frac{\partial f}{\partial e_1}(a) & \cdots & \frac{\partial f}{\partial e_n}(a)
      \end{bmatrix} = \begin{bmatrix}
        \frac{\partial f_1}{\partial e_1}(a) & \cdots & \frac{\partial f_1}{\partial e_n}(a) \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f_m}{\partial e_1}(a) & \cdots & \frac{\partial f_m}{\partial e_n}(a) \\
      \end{bmatrix}
    \end{array}
  \end{equation}

  $(e_i)_{i \in \llbracket 1,n \rrbracket}$ means the matrices $e_i = \begin{bmatrix}
    0 & \cdots & \underset{\text{at column $i$}} 1 & \cdots & 0
  \end{bmatrix}$ corresponding to $\Real^n$ standard basis. \par
  $\frac{\partial f}{\partial e_i}$ is named the partial derivative of $f$ according the $i^{th}$ variable. \par
  The jacobian is also named gradient when $m=1$ and is noted as $\nabla_f = \mathcal{J}_f$. \par
  The jacobian is also named derivative when $m=1$ with $n=1$ and is noted as $f' = \nabla_f = \mathcal{J}_f$.
\end{definition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $a \in \mathring{E}$ and $h \in \Real^n$.
  \begin{equation*}
    \begin{split}
      f_i (a + h) & = f(a + h)_i \\
      & = f(a)_i + \frac{\partial f}{\partial h}(a)_i + \underset{h \to 0}o(\norm h _n)_i \\
      & = f_i(a) + \frac{\partial f}{\partial h}(a)_i + \underset{h \to 0}o(\norm h _n)_i
    \end{split}
  \end{equation*}
  \begin{equation*}
    \frac{\partial f}{\partial \cdot}(a)_i \in \mathcal{L}(\Real^n,\Real) \underset{prop\ref{prop:differential_unique}}\implies \frac{\partial f_i}{\partial h}(a) = \frac{\partial f}{\partial h}(a)_i
  \end{equation*}
\end{proof}

% Jacobian definition corollary
\begin{corollary}
  {\normalfont Let $E \subseteq \Real^n$, $F \subseteq \Real^m$ and $f \in \mathcal{D}(E,F)$.
  The jacobian of $f$ on $a \in \mathring{E}$ fixed is the canonical associated matrix to the differential of $f$ on $a$.} \par
  \normalfont{\textbf{Notes:} It means a function differentiability can also be proved by exhibing its jacobian.} \par
\end{corollary}

\begin{proof}
  Let $a \in \mathring{E}$.
  $\frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n,\Real^m)$ and any linear application in finite dimension
  with values in $\Real$ has an unique associated matrix in the standard basis called canonical associated matrix. \par
\end{proof}

% Jacobian of two applications sum
\begin{proposition}\label{prop:jacobians_sum}
  {\normalfont
    Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $f \in \mathcal{D}(E,F)$ and $g \in \mathcal{D}(E,F)$.
    Then $g + f \in \mathcal{D}(E,F)$ and \begin{equation}
      \begin{array}{llll}
        \mathcal{J}_{g + f} & : & \mathring{E} & \longrightarrow F \\
        &   & a & \longmapsto \mathcal{J}_{g}(a) + \mathcal{J}_{f}(a)
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $a \in \mathring{E}$ and $h \in \Real^n$.
  \begin{equation*}
    \begin{split}
      (g + f)(a+h) & = g(a+h) + f(a+h) \\
      & \underset{(\ref{def:differentiable})}{=} g(a) + f(a) + \frac{\partial g}{\partial h}(a) + \frac{\partial f}{\partial h}(a) + 2 * \underset{h \to 0}o(\norm h _n) \\
      & = (g + f)(a) + \frac{\partial g}{\partial h}(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)
    \end{split}
  \end{equation*}

  \begin{equation*}
    \begin{split}
      \frac{\partial g}{\partial \cdot}(a) + \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n, \Real^m)
      & \underset{prop\ref{prop:differential_unique}}\implies g + f \in \mathcal{D}(E,F), \frac{\partial (g + f)}{\partial \cdot}(a) = \frac{\partial g}{\partial \cdot}(a) + \frac{\partial f}{\partial \cdot}(a) \\
      & \underset{mat}\implies \mathcal{J}_{g + f}(a) = \mathcal{J}_{g}(a) + \mathcal{J}_{f}(a)
    \end{split}
  \end{equation*} \par

  \textbf{Note:} $mat$ indicates in canonical associated matrix way. \par
\end{proof}

% Function composition notation
\begin{notation}
  Let $f \in \mathcal{F}(E,F)$ and $g \in \mathcal{F}(F,G)$.
  Then the notation $g \circ f$ means the application \begin{equation*}
    \begin{array}{llll}
      g \circ f & : & E & \longrightarrow G \\
        &   & x & \longmapsto g(f(x))
    \end{array}
  \end{equation*} \par

  Let $f_i \in \mathcal{F}(E_i,E_{i+1})$ for $i \in \llbracket 1,n \rrbracket$.
  Then the notation $\underset{i=1}{\overset{n}\circ} f_i$ means the application \begin{equation*}
    \begin{array}{llll}
      \underset{i=1}{\overset{n}\circ} f_i & : & E_1 & \longrightarrow E_{n+1} \\
        &   & x & \longmapsto f_n( \ldots f_2(f_1(x)))
    \end{array}
  \end{equation*}
\end{notation}

% Chain rule
\begin{theorem}\label{theo:chain_rule}
  {\normalfont
    Let $E \subseteq \Real^n$, $F \subseteq \Real^m$, $G \subseteq \Real^p$, $f \in \mathcal{D}(E,F)$ and $g \in \mathcal{D}(F,G)$.
    Then $g \circ f \in \mathcal{D}(E,G)$ and \begin{equation}\label{theo:chain_rule_eq}
      \begin{array}{llll}
        \mathcal{J}_{g \circ f} & : & \mathring{E} & \longrightarrow G \\
        &   & a & \longmapsto \mathcal{J}_{g}(f(a)) * \mathcal{J}_{f}(a)
      \end{array}
    \end{equation} \par
    \textbf{Note:} This theorem is named the chain rule.
  }
\end{theorem}

\begin{proof}
  Let $a \in \mathring{E}$ and $h \in \Real^n$.
  \begin{equation*}
    \begin{split}
      (g \circ f)(a+h) & = g(f(a) + \frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)) \\
      & = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n))}(f(a))
        + \underset{h \to 0}o(\norm{\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n)}_n) \\
      & \underset{\frac{\partial f}{\partial \cdot}(a) \in \mathcal{C}(\Real^n,\Real^m),\frac{\partial f}{\partial 0_{\Real^n}}(a) = 0_{\Real^m}}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a) + \underset{h \to 0}o(\norm h _n))}(f(a)) + \underset{h \to 0}o(\norm h _n) \\
      & \underset{\frac{\partial g}{\partial \cdot}(a) \in \mathcal{L}(\Real^m,\Real^p)}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a))}(f(a)) + \frac{\partial g}{\partial (\underset{h \to 0}o(\norm h _n))}(f(a)) + \underset{h \to 0}o(\norm h _n) \\
      & \underset{\frac{\partial g}{\partial \cdot}(a) \in \mathcal{C}(\Real^m,\Real^p),\frac{\partial g}{\partial 0_{\Real^m}}(a) = 0_{\Real^p}}
        = g(f(a)) + \frac{\partial g}{\partial (\frac{\partial f}{\partial h}(a))}(f(a)) + \underset{h \to 0}o(\norm h _n)
    \end{split}
  \end{equation*}
  \begin{equation*}
    \begin{split}
      \frac{\partial g}{\partial (\frac{\partial f}{\partial \cdot}(a))}(f(a)) = \frac{\partial g}{\partial \cdot}(f(a)) \circ \frac{\partial f}{\partial \cdot}(a) \in \mathcal{L}(\Real^n, \Real^p)
      & \underset{prop\ref{prop:differential_unique}}\implies g \circ f \in \mathcal{D}(E,G), \frac{\partial (g \circ f)}{\partial \cdot}(a) = \frac{\partial g}{\partial \cdot}(f(a)) \circ \frac{\partial f}{\partial \cdot}(a) \\
      & \underset{mat}\implies \mathcal{J}_{g \circ f}(a) = \mathcal{J}_{g}(f(a)) * \mathcal{J}_{f}(a)
    \end{split}
  \end{equation*} \par

  \textbf{Note:} $mat$ indicates in canonical associated matrix way. \par
\end{proof}

\subsection{Others}

% Cartesian products
\begin{notation}
  Let $E$ and $F$ two sets and $(E_i)_{i \in \llbracket 1,n \rrbracket}$ $n$ sets. \par
  The notation $E \times F$ means the cartesian product between $E$ and $F$. \par
  The notation $\underset{i=1}{\overset{n}\circ} E_i$ means the cartesian product $E_n \times \ldots \times E_1$.
\end{notation}

% Kronecker delta
\begin{notation}
  The notation $\delta_{\cdot,\cdot}$ means the kronecker delta application \begin{equation*}
    \begin{array}{llll}
      \delta_{\cdot,\cdot} & : & \mathbb{Z} \times \mathbb{Z} & \longrightarrow \{0,1\} \\
      &   & (i,j) & \longmapsto \begin{array}{ll}
        1 & i = j \\
        0 & i \neq j
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Indicator function
\begin{notation}
  Let $E \subseteq \Real^n$. The notation $\mathbb{1}_E$ means the indicator function of $E$ on $\Real^n$.
  \begin{equation*}
    \begin{array}{llll}
      \mathbb{1}_E & : & E & \longrightarrow \{0,1\}^n \\
      &   & x & \longmapsto \begin{array}{ll}
        1 & x \in E \\
        0 & x \notin E
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Max function
\begin{notation}
  The notation $max(0,\cdot)$ means the application
  \begin{equation*}
    \begin{array}{llll}
      max(0,\cdot) & : & \Real & \longrightarrow \Real^+ \\
      &   & x & \longmapsto \begin{array}{ll}
        x & x > 0 \\
        0 & x \leq 0
      \end{array}
    \end{array}
  \end{equation*}
\end{notation}

% Max differential assumption
\begin{assumption}\label{assump:max_differentiable}
  $max(0,\cdot) \in \mathcal{D}(\Real, \Real^+)$ with
  \begin{equation*}
    \begin{array}{lllll}
      max(0,\cdot)' & : & \Real & \longrightarrow \Real^+ \\
      &   & x & \longmapsto \mathbb{1}_{\Real^{+*}}(x)
    \end{array}
  \end{equation*}\par

  \textbf{Note:} $max(0,\cdot)$ is actually not \textit{differentiable} on $0$ and the notation $\Real^{*}$ means $\Real_{\backslash\{0\}}$. \par
\end{assumption}

% Fixed variable function
\begin{notation}
  Let $f$ an application with $n$ inputs and $m$ outputs.
  \begin{equation*}
    \begin{array}{llll}
      f & : & E_1 \times \ldots \times E_n & \longrightarrow F_1 \times \ldots \times F_m \\
      &   & (x_1, \ldots, x_n) & \longmapsto f(x_1, \ldots, x_n)
    \end{array}
  \end{equation*} \par

  Let $k \in \llbracket 1,n \rrbracket$. The notation $f(x_1, \ldots, x_{k-1}, \cdot, x_{k+1}, \ldots, x_n)$ means \begin{equation*}
    \begin{array}{llll}
      f(x_1, \ldots, x_{k-1}, \cdot, x_{k+1}, \ldots, x_n) & : & E_k & \longrightarrow F_1 \times \ldots \times F_m \\
      &   & x_k & \longmapsto f(x_1, \ldots, x_{k-1}, x_k, x_{k+1}, \ldots, x_n)
    \end{array}
  \end{equation*}
\end{notation}

\section{Activation functions}

% Act function notation
\begin{notation}
  Let $E \subseteq \Real^m \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{act}(E,F)$ means the set of activation functions from $E$ to $F$. \par
  \textbf{Note:} An activation function is an application defined in this section. \par
\end{notation}

% ReLU definition
\begin{definition}
  Let the activation function \textit{ReLU} noted as $\mathcal{R}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathcal{R} & : & \Real^m & \longrightarrow \Real^m \\
      &   & z & \longmapsto \begin{bmatrix}
        max(0,z_1) \\
        \vdots \\
        max(0,z_m)
      \end{bmatrix}
    \end{array}
  \end{equation*} \par
\end{definition}

% ReLU differential
\begin{proposition}
  {\normalfont
    $\mathcal{R} = (\mathcal{R}_1 \ldots \mathcal{R}_m) \in \mathcal{D}(\Real^m,\Real^m)$ and its jacobian is \begin{equation}\label{prop:relu_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathcal{R}} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & z & \longmapsto \begin{bmatrix}
          \mathbb{1}_{\Real^{+*}}(z_1) & 0 & \cdots & 0 \\
          0 & \mathbb{1}_{\Real^{+*}}(z_2) & \ddots & \vdots \\
          \vdots & \ddots & \ddots & 0 \\
          0 & \cdots & 0 & \mathbb{1}_{\Real^{+*}}(z_m) \\
        \end{bmatrix}
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$.
  \begin{equation*}
    \begin{split}
      \mathcal{R}_i(z) = max(0,z_i) & \underset{assump\ref{assump:max_differentiable}}\implies \frac{\partial \mathcal{R}_i}{\partial e_j}(z)
        = \begin{array}{ll}
          \mathbb{1}_{\Real^{+*}}(z_i) & i = j \\
          0 & i \neq j
      \end{array}
    \end{split}
  \end{equation*}
\end{proof}

% Softmax definition
\begin{definition}
  Let the activation function \textit{Softmax} noted as $\mathcal{S}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathcal{S} & : & \Real^m & \longrightarrow ]0,1[^m \\
      &   & z & \longmapsto \begin{bmatrix}
        \frac{e^{z_1}}{\sum_{k=1}^m e^{z_k}} \\
        \vdots \\
        \frac{e^{z_m}}{\sum_{k=1}^m e^{z_k}}
      \end{bmatrix}
    \end{array}
  \end{equation*} \par
\end{definition}

% Softmax differential
\begin{proposition}
  {\normalfont
    $\mathcal{S} = (\mathcal{S}_1 \ldots \mathcal{S}_m) \in \mathcal{D}(\Real^m,]0,1[^m)$ and its jacobian is \begin{equation}\label{prop:softmax_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathcal{S}} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & z & \longmapsto \begin{bmatrix}
          \mathcal{S}_1 * (1 - \mathcal{S}_1) & - \mathcal{S}_1 * \mathcal{S}_2 & \cdots & - \mathcal{S}_1 * \mathcal{S}_m \\
          - \mathcal{S}_2 * \mathcal{S}_1 & \mathcal{S}_2 * (1 - \mathcal{S}_2) & \ddots & \vdots \\
          \vdots & \ddots & \ddots & - \mathcal{S}_{m-1} * \mathcal{S}_m \\
          - \mathcal{S}_m * \mathcal{S}_1 & \cdots & - \mathcal{S}_m * \mathcal{S}_{m-1} & \mathcal{S}_m * (1 - \mathcal{S}_m) \\
        \end{bmatrix} (z)
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \mathcal{S}_i(z) = \frac{e^{z_i}}{\sum_{k=1}^m e^{z_k}}
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{lll}
      & \implies \frac{\partial \mathcal{S}_i}{\partial e_j} (z) & = \frac{(\delta_{i,j} * e^{z_i}) * {\sum_{k=1}^m e^{z_k}} - e^{z_j} * e^{z_i}}{(\sum_{k=1}^m e^{z_k})^2} \\
      & & = \delta_{i,j} * \mathcal{S}_i(z) - \mathcal{S}_j(z) * \mathcal{S}_i(z) \\
      & & = \mathcal{S}_i(z) * (\delta_{i,j} - \mathcal{S}_j(z))
    \end{array}
  \end{equation*}
\end{proof}

\section{Loss}

% Loss function notation
\begin{notation}
  Let $E \subseteq \Real^m \times \Real^m$, $F \subseteq \Real$. \par
  The notation $\mathcal{F}_{loss}(E,F)$ means the set of loss functions from $E$ to $F$. \par
  \textbf{Note:} A loss function is an application defined in this section. \par
\end{notation}

% Categorical cross-entropy loss definition
\begin{definition}
  Let the loss function \textit{Categorical cross-entropy} noted as $\xi$ be
  \begin{equation*}
    \begin{array}{llll}
      \xi & : & ]0,1[^m \times \{0,1\}^m & \longrightarrow \Real \\
      &   & (y,y^*) & \longmapsto - \sum_{k=1}^m y_k^* * \log(y_k)
    \end{array}
  \end{equation*} \par
\end{definition}

% Categorical cross-entropy loss differential
\begin{proposition}
  {\normalfont
    Let $y^* \in \{0,1\}^m$. $\xi(\cdot,y^*) \in \mathcal{D}(]0,1[^m, \Real)$ and its gradient is \begin{equation}\label{prop:cce_differential}
      \begin{array}{llll}
        \nabla_{\xi(\cdot,y^*)} & : & ]0,1[^m  & \longrightarrow \Real \\
        &   & y & \longmapsto - \begin{bmatrix}
          \frac{y^*_1}{y_1} & \ldots & \frac{y^*_m}{y_m}
        \end{bmatrix}
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $y \in ]0,1[^m$. \begin{equation*}
    \begin{array}{lll}
      \xi(y,y^*) = - \sum_{k=1}^m y_k^* * \log(y_k) & \implies \frac{\partial \xi(\cdot,y^*)}{\partial e_j} (y) & = - \frac{y_j^*}{y_j}
    \end{array}
  \end{equation*}
\end{proof}

\section{Layers}

% Layers notation
\begin{notation}
  Let $E \subseteq \Real^n \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{layer}(E,F)$ means the set of layer functions from $E$ to $F$. \par
  \textbf{Note:} A layer function is an application defined in this section. \par
\end{notation}

% Dense layer definition
\begin{definition}
  Let the layer function \textit{Dense layer} noted as $\mathbb{L}$ be
  \begin{equation*}
    \begin{array}{llll}
      \mathbb{L} & : & \Real^n \times \mathcal{M}_{m,n} \times \Real^m & \longrightarrow \Real^m \\
      &   & (y,W,b) & \longmapsto y * W^T + b
    \end{array}
  \end{equation*} \par
  \textbf{Note:} $\mathbb{L} : \Real^n \times \mathcal{M}_{m,n} \times \Real^m \longrightarrow \Real^m$
  is equivalent to $\mathbb{L} : \Real^n \times (\Real^n)^{m} \times \Real^m \longrightarrow \Real^m$.
\end{definition}

% Dense layer differential on y
\begin{proposition}
  {\normalfont
    Let $W \in \mathcal{M}_{m,n}$ and $b \in \Real^m$.
    $\mathbb{L}(\cdot,W,b) = (\mathbb{L}_1(\cdot,W,b) \ldots \mathbb{L}_m(\cdot,W,b)) \in \mathcal{D}(\Real^n, \Real^m)$
    and its gradient is \begin{equation}\label{prop:densel_y_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(\cdot,W,b)} & : & \Real^n  & \longrightarrow \mathcal{M}_{m,n} \\
        &   & y & \longmapsto W
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$
  and $y \in \Real^n$. \begin{equation*}
    \begin{array}{lll}
      \mathbb{L}(y,W,b) = y * W^T + b & \implies \mathbb{L}_i(y,W,b) & = y * W_{i,:}^T + b_i \\
      & \implies \frac{\partial \mathbb{L}_i(\cdot,W,b)}{\partial e_j} (y) & = W_{i,j}
    \end{array}
  \end{equation*}
\end{proof}

% Dense layer differential on W
\begin{proposition}
  {\normalfont
    Let $y \in \Real^n$, $(w^{(k)})_{k \in \llbracket 1,m-1 \rrbracket} \in (\Real^n)^{m-1}$, $b \in \Real^m$. \par
    $\forall i^* \in \llbracket 1,m \rrbracket,$
    $\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\underset{\text{at index $i^*$}}{\cdot},w^{(i^*)},\ldots,w^{(m-1)},b) \in \mathcal{D}(\Real^n, \Real^m)$
    and jacobians are \begin{equation*}
      \begin{gathered}
        \forall i^* \in \llbracket 1,m \rrbracket,
      \end{gathered}
    \end{equation*}
    \begin{equation}\label{prop:densel_W_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)} & : & \Real^n  & \longrightarrow \mathcal{M}^{m,n} \\
        &   & w & \longmapsto \begin{bmatrix}
          & (0) & \\
          y_1 & \cdots & y_n \\
          & (0) &
        \end{bmatrix} \text{\small{at row $i^*$}}
      \end{array}
    \end{equation} \par
    \textbf{Note:} For $i^*=1$ and $i^*=m$,
    the applications $\mathbb{L}(y,\cdot,w^{(1)},\ldots,w^{(m-1)},b)$ and $\mathbb{L}(y,w^{(1)},\ldots,w^{(m-1)},\cdot,b)$ are meant respectively.
  }
\end{proposition}

\begin{proof}
  Let $i^* \in \llbracket 1,m \rrbracket$, $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$ and $w \in \Real^n$. \begin{equation*}
    \begin{gathered}
      \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)(w) \\
      = \begin{bmatrix}
        y * {w^{(1)}}^T &
        \cdots &
        y * {w^{(i^*-1)}}^T &
        y * w^T &
        y * {w^{(i^*)}}^T &
        \cdots &
        y * {w^{(m-1)}}^T
      \end{bmatrix} + b
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{gathered}
      \implies \frac{\partial \mathbb{L}_i(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}{\partial e_j} (w) = \begin{array}{ll}
        y_j & i = i^* \\
        0 & i \neq i^*
      \end{array}
    \end{gathered}
  \end{equation*}
\end{proof}

% Dense layer differential on b
\begin{proposition}
  {\normalfont
    Let $y \in \Real^n$ and $W \in \mathcal{M}_{m,n}$.
    $\mathbb{L}(y,W,\cdot) = (\mathbb{L}_1(y,W,\cdot) \ldots \mathbb{L}_m(y,W,\cdot)) \in \mathcal{D}(\Real^m, \Real^m)$
    and its gradient is \begin{equation}\label{prop:densel_b_differential}
      \begin{array}{llll}
        \mathcal{J}_{\mathbb{L}(y,W,\cdot)} & : & \Real^m  & \longrightarrow \mathcal{M}_{m,m} \\
        &   & b & \longmapsto I_m
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $i \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$
  and $b \in \Real^m$. \begin{equation*}
    \begin{array}{lll}
      \mathbb{L}(y,W,b) = y * W^T + b & \implies \mathbb{L}_i(y,W,b) & = y * W_{i,:}^T + b_i \\
      & \implies \frac{\partial \mathbb{L}_i(y,W,\cdot)}{\partial e_j} (b) & = \delta_{i,j}
    \end{array}
  \end{equation*}
\end{proof}

\section{Neural networks}

\subsection{Simplified jacobian matrices}

% F^upstream circ ReLU differential
\begin{proposition}
  {\normalfont
    Let $\mathcal{F}^{(upstream)} \in \mathcal{D}(\Real^m,\Real)$ and
    $\mathcal{R} \in \mathcal{F}_{act}(\Real^m,\Real^m)$.
    $\mathcal{F}^{(upstream)} \circ \mathcal{R} \in \mathcal{D}(\Real^m,\Real)$ and its gradient is \begin{equation} \label{prop:relu_simplified_differential}
      \begin{array}{llll}
        \nabla_{\mathcal{F}^{(upstream)} \circ \mathcal{R}} & : & \Real^m  & \longrightarrow \Real^m \\
        &   & z & \longmapsto \begin{bmatrix}
          \nabla_{\mathcal{F}^{(upstream)}}(y)_1 * \mathbb{1}_{\Real^{+*}}(z_1) & \cdots &
            \nabla_{\mathcal{F}^{(upstream)}}(y)_m * \mathbb{1}_{\Real^{+*}}(z_m)
        \end{bmatrix}
      \end{array}
    \end{equation} \par
    where \begin{equation*}
      y = \mathcal{R}(z)
    \end{equation*}

    \textbf{Note:} It means such a gradient can be implemented without matrix multiplication.
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$.
  \begin{equation*}
    \begin{split}
      \nabla_{\mathcal{F}^{(upstream)} \circ \mathcal{R}} \underset{(\ref{theo:chain_rule_eq})}{=}
        \nabla_{\mathcal{F}^{(upstream)}}(\mathcal{R}(z)) * \mathcal{J}_{\mathcal{R}}(z) &
      \underset{(\ref{prop:relu_differential})}\implies \frac{\partial \mathcal{F}^{(upstream)} \circ \mathcal{R}}{\partial e_j}(z)
        = \nabla_{\mathcal{F}^{(upstream)}}(\mathcal{R}(z))_j * \mathbb{1}_{\Real^{+*}}(z_j)
    \end{split}
  \end{equation*}
\end{proof}

% F^upstream circ Dense layer differential on W
\begin{proposition}
  {\normalfont
    Let $\mathcal{F}^{(upstream)} \in \mathcal{D}(\Real^m,\Real)$,
      $\mathbb{L} \in \mathcal{F}_{layer}(\Real^n \times (\Real^n)^m \times \Real^m,\Real^m)$,
      $y \in \Real^n$, $(w^{(k)})_{k \in \llbracket 1,m-1 \rrbracket} \in (\Real^n)^{m-1}$ and $b \in \Real^m$. \par
    $\forall i^* \in \llbracket 1,m \rrbracket,$
    $\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\underset{\text{at index $i^*$}}{\cdot},w^{(i^*)},\ldots,w^{(m-1)},b) \in \mathcal{D}(\Real^n, \Real)$
    and gradients are \begin{equation*}
      \begin{gathered}
        \forall i^* \in \llbracket 1,m \rrbracket,
      \end{gathered}
    \end{equation*}
    \begin{equation} \label{prop:densel_W_simplified_differential}
      \begin{array}{llll}
        \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)} & : & \Real^n  & \longrightarrow \Real^n \\
        &  & w & \longmapsto \nabla_{\mathcal{F}^{(upstream)}}(z)_{i^*} * y
      \end{array}
    \end{equation} \par
    where \begin{equation*}
      z = \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},w,w^{(i^*)},\ldots,w^{(m-1)},b)
    \end{equation*}

    \textbf{Note:} It means these gradients for $i^* \in \llbracket 1,m \rrbracket$ can be implemented with $\nabla_{\mathcal{F}^{(upstream)}}(z)^T * y$.
  }
\end{proposition}

\begin{proof}
  Let $i^* \in \llbracket 1,m \rrbracket$, $j \in \llbracket 1,n \rrbracket$ and $w \in \Real^n$.
  Let $z = \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},w,w^{(i^*)},\ldots,w^{(m-1)},b)$. \begin{equation*}
    \begin{gathered}
      \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}(w)
        \underset{(\ref{theo:chain_rule_eq})}{=} \nabla_{\mathcal{F}^{(upstream)}}(z) *
        \mathcal{J}_{\mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}(w)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{gathered}
      \underset{(\ref{prop:densel_W_differential})}{\implies}
        \frac{\partial \nabla_{\mathcal{F}^{(upstream)} \circ \mathbb{L}(y,w^{(1)},\ldots,w^{(i^*-1)},\cdot,w^{(i^*)},\ldots,w^{(m-1)},b)}}{\partial e_j} (w)
        = \nabla_{\mathcal{F}^{(upstream)}}(z)_{i^*} * y_j
    \end{gathered}
  \end{equation*}
\end{proof}

% Categorical cross-entropy loss composed with Softmax differential
\begin{proposition}
  {\normalfont
    Let $\mathcal{S} \in \mathcal{F}_{act}(\Real^m,]0,1[^m)$ and $\xi \in \mathcal{F}_{loss}(]0,1[^m \times \{0,1\}^m, \Real)$. \par
    Let $y^* \in \{0,1\}^m$ with $\norm{y^*}_m = 1$.
    $\xi(\cdot,y^*) \circ \mathcal{S} \in \mathcal{D}(\Real^m,\Real)$ and its gradient is \begin{equation}\label{prop:cce_softmax_differential}
      \begin{array}{llll}
        \nabla_{\xi(\cdot,y^*) \circ \mathcal{S}} & : & \Real^m  & \longrightarrow \Real \\
        &   & z & \longmapsto \mathcal{S}(z) - y^*
      \end{array}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $j \in \llbracket 1,m \rrbracket$ and $z \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \nabla_{\xi(\cdot,y^*) \circ \mathcal{S}}(z) \underset{(\ref{theo:chain_rule_eq})}{=} \nabla_{\xi(\cdot,y^*)}(\mathcal{S}(z)) * \mathcal{J}_{\mathcal{S}}(z)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{lll}
      & \implies \frac{\partial \xi(\cdot,y^*) \circ \mathcal{S}}{\partial e_j} (z)
        & \underset{(\ref{prop:softmax_differential}),(\ref{prop:cce_differential})}= - y_j^* + \sum_{k=1}^m {y_k^* * \mathcal{S}_j(z)} \\
      & & \underset{y^* \in \{0,1\}^m, \norm{y}_m = 1}{=} \mathcal{S}_j(z) - y_j^*
    \end{array}
  \end{equation*}
\end{proof}

\subsection{Definitions}

% Neural network notation
\begin{notation}
  Let $E \subseteq \Real^n \times (\Real^{\cdot})^p$ ($p$ parameter vectors of any sizes) and $F \subseteq \Real^m$. \par
  The notation $\mathcal{F}_{net}(E,F)$ means the set of neural network functions from $E$ to $F$. \par
  \textbf{Note:} A neural network is an application defined in this section. \par
\end{notation}

% Multi-Class DNN definition
\begin{definition}
  Let $(m_k)_{k \in \llbracket 0,p \rrbracket} \in (\mathbb{N}^*)^p$. Let the neural network
  \textit{Multi-class dense neural network} noted as $\mathcal{N}_{c^+}$ be \begin{equation*}
    \begin{array}{llll}
      \mathcal{N}_{c^+} & : & \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ) & \longrightarrow \Real^{m_p} \\
      &   & (x,(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket}) & \longmapsto
      ( \mathcal{S} \circ \mathbb{L}^{(p)}(\cdot, W^{(p)}, b^{(p)}) ) \circ ( \underset{k=1}{\overset{p-1}{\circ}} \mathcal{R}^{(k)} \circ \mathbb{L}^{(k)}(\cdot, W^{(k)}, b^{(k)}) ) (x)
    \end{array}
  \end{equation*} \par

  where \begin{equation*}
    \begin{array}{ll}
      & (\mathbb{L}^{(k)})_{k \in \llbracket 1,p \rrbracket} \in
        \underset{k=1}{\overset{p}{\times}} \mathcal{F}_{layer}(\Real^{m_{k-1}} \times \mathcal{M}_{m_{k},m_{k-1}} \times \Real^{m_{k}}, \Real^{m_{k}}) \\
      & (\mathcal{R}^{(k)})_{k \in \llbracket 1,p-1 \rrbracket} \in
        \underset{k=1}{\overset{p-1}{\times}} \mathcal{F}_{act}(\Real^{m_k}, \Real^{m_k}) \\
      & \mathcal{S} \in \mathcal{F}_{act}(\Real^{m_p}, ]0,1[^{m_p})
    \end{array}
  \end{equation*}
  
  \textbf{Note:} $\mathcal{N}_{c^+} : \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )
    \longrightarrow \Real^{m_p}$
  is equivalent to $\mathcal{N}_{c^+} : \Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )
  \longrightarrow \Real^{m_p}$.
\end{definition}

% Multi-Class DNN properties
\begin{corollary}
  \normalfont{
    $\mathcal{N}_{c^+} \in \mathcal{D}(\Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real^{m_p})$
    and the total number of parameter is \begin{equation*}
      \sum_{k=1}^{p} m_{k} * (m_{k-1} + 1)
    \end{equation*}
  }
\end{corollary}

\begin{proof}
  $\mathcal{N}_{c^+}$ is a composition of \textit{differentiable} applications so it is \textit{differentiable} by the \hyperref[theo:chain_rule]{chain rule} theorem.
  Let $a \in ( \underset{k=1}{\overset{p}{\times}} (\Real^{m_{k-1}})^{m_k} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} )$
  then $a$ has $\sum_{k=1}^{p} m_{k} * m_{k-1} + \sum_{k=1}^{p} m_{k}$ coefficients. \par
\end{proof}

% Multi-Class DNN objective function
\begin{definition}
  Let $(m_k)_{k \in \llbracket 0,p \rrbracket}$, $\mathcal{N}_{c^+} \in
    \mathcal{F}_{net}(\Real^{m_0} \times ( \underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real^{m_p})$,
    $X = (x^{(i)})_{i \in \llbracket 1,n \rrbracket} \in (\Real^{m_0})^n$
    and $Y^* = ({y^*}^{(i)})_{i \in \llbracket 1,n \rrbracket} \in (\{0,1\}^{m_p})^n$ with $\forall i \in \llbracket 1,n \rrbracket$, $\norm{{y^*}^{(i)}}_{m_p} = 1$. \par
  Let the \textit{Multi-class optimization problem} noted as $(\mathcal{P}_{c^+})$ be \begin{mini}
    {(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket}}
    {\sum_{i=1}^{n}{\xi(y^{(i)},{y^*}^{(i)})}}
    {}{(\mathcal{P}_{c^+})\text{ : }}
  \end{mini} \par
  where \begin{equation*}
    \begin{array}{ll}
      & \xi \in \mathcal{F}_{loss}(]0,1[^{m_p} \times \{0,1\}^{m_p}, \Real) \\
      & y^{(i)} = \mathcal{N}_{c^+}(x^{(i)},(W^{(k)})_{k \in \llbracket 1,p \rrbracket},(b^{(k)})_{k \in \llbracket 1,p \rrbracket})
    \end{array}
  \end{equation*} \par

  $\sum_{i=1}^{n} \xi (\cdot, {y^*}^{(i)}) \circ \mathcal{N}_{c^+}(x^{(i)},\cdot,\cdot)$ is named the objective function
  and will be noted as $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$.
\end{definition}

% Multi-Class DNN objective function differentiability
\begin{corollary}
  {\normalfont
    $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot) \in \mathcal{D}((\underset{k=1}{\overset{p}{\times}} \mathcal{M}_{m_{k},m_{k-1}} ) \times ( \underset{k=1}{\overset{p}{\times}} \Real^{m_{k}} ), \Real)$. \par
    \textbf{Note:} Its gradients for each variable can be computed recursively through each composition using
    $(\ref{prop:jacobians_sum})$, $(\ref{theo:chain_rule_eq})$,
    $(\ref{prop:densel_y_differential})$, $(\ref{prop:densel_W_simplified_differential})$, $(\ref{prop:densel_b_differential})$,
    $(\ref{prop:relu_simplified_differential})$ and $(\ref{prop:cce_softmax_differential})$.
  }
\end{corollary}

\begin{proof}
  $\mathcal{O}_{c^+}(X,Y^*,\cdot,\cdot)$ is a sum and composition of \textit{differentiable} applications so it is \textit{differentiable} by the proposition $\ref{prop:jacobians_sum}$ and \hyperref[theo:chain_rule]{chain rule} theorem. \par
\end{proof}

% Gradient descent
\section{Gradient descent}

\subsection{Optimization fundamentals}

% Applicaton convex
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$. $f$ \textit{convex} means \begin{equation}\label{def:convex_eq}
    \begin{gathered}
      \forall x \in \Real^m, \forall y \in \Real^m, \\
      \forall \tau \in [0,1], f(\tau * x + (1 - \tau) * y) \leq \tau * f(x) + (1 - \tau) * f(y)
    \end{gathered}
  \end{equation}
\end{definition}

% Application convex equivalent with gradient
\begin{proposition}
  {\normalfont
    Let $f \in \mathcal{D}(\Real^m,\Real)$. $f$ \textit{convex} is equivalent to \begin{equation}\label{prop:convex_grad}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        f(x) + \nabla_f(x) * (y - x)^T \leq f(y)
      \end{gathered}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Suppose $f$ \textit{convex} $(\ref{def:convex_eq})$. Let $x \in \Real^m$ and $y \in \Real^m$. \begin{equation*}
    \begin{gathered}
      \forall \tau \in ]0,1[,
      f(x + \tau * (y - x)) \underset{\norm{\cdot}_m \in \mathcal{C}(\Real^m,\Real),f \in \mathcal{D}(\Real^m,\Real),(\ref{def:differentiable})}{=}
        f(x) + \frac{\partial f}{\partial (\tau * (y - x))}(x) + \underset{\tau \to 0}o(\norm{\tau * (y - x)}_m)
    \end{gathered}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      & \underset{(\ref{def:convex_eq})}{\implies}
        \forall \tau \in ]0,1[,
        f(x) + \frac{\partial f}{\partial (\tau * (y - x))}(x) + \underset{\tau \to 0}o(\norm{\tau * (y - x)}_m)
        \leq \tau * f(y) + (1 - \tau) * f(x) \\
      & \underset{\frac{\partial f}{\partial \cdot} \in \mathcal{L}(\Real^m,\Real)}{\implies}
        \forall \tau \in ]0,1[,
        \frac{\partial f}{\partial (y - x)}(x) + \underset{\tau \to 0}o(\norm{y - x}_m)
        \leq f(y) - f(x) \\
      & \underset{\tau \to 0}{\implies}
        \frac{\partial f}{\partial (y - x)}(x) \leq f(y) - f(x) \\
      & \underset{mat}{\implies}
        f(x) + \nabla_f(x) * (y - x)^T \leq f(y)
    \end{array}
  \end{equation*} \par \par

  Suppose $(\ref{prop:convex_grad})$. Let $x \in \Real^m$, $y \in \Real^m$ and $\tau \in [0,1]$. Let $z = \tau * x + (1 - \tau) * y$.
  \begin{equation*}
    \begin{array}{lll}
      (a) : & f(z) - (1 - \tau) * \nabla_f(z) * (y - x)^T & \underset{(\ref{prop:convex_grad})}{=} f(z) + \nabla_f(z) * (x - z)^T \leq f(x) \\
      (b) : & f(y) + \tau * \nabla_f(z) * (y - x)^T & \underset{(\ref{prop:convex_grad})}{=} f(z) + \nabla_f(z) * (y - z)^T \leq f(y)
    \end{array}
  \end{equation*}
  \begin{equation*}
    \underset{\tau * (a) + (1 - \tau) * (b)}{\implies} f(z) \leq \tau * f(x) + (1 - \tau) f(y)
  \end{equation*}
\end{proof}

% L-smooth definition
\begin{definition}
  Let $f \in \mathcal{D}(\Real^m,\Real)$ and $L \in \Real^{+*}$. $f$ \textit{L-smooth} means \begin{equation}\label{def:lsmooth_eq}
    \begin{gathered}
      \forall x \in \Real^m, \forall y \in \Real^m, \\
      \norm{\nabla_f(x) - \nabla_f(y)}_m \leq L * \norm{x - y}_m 
    \end{gathered}
  \end{equation}
\end{definition}

% L-smooth proposition
\begin{proposition}
  {\normalfont
    Let $f \in \mathcal{D}(\Real^m,\Real)$ and $L \in \Real^{+*}$. If $f$ \textit{L-smooth} then \begin{equation}\label{prop:lsmooth_implies}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        f(y) \leq f(x) + \nabla_f(x) * (y - x)^T + \frac{L}{2} * \norm{y - x}_m^2
      \end{gathered}
    \end{equation}
  }
\end{proposition}

\begin{proof}
  Let $x \in \Real^m$ and $y \in \Real^m$. Let \begin{equation*}
    \begin{array}{llll}
      g & : & [0,1] & \longrightarrow \Real^m \\
      & & \tau & \longrightarrow x + \tau * (y - x)
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      \forall \tau \in [0,1], (f \circ g)(\tau) = f(x + \tau * (y - x)) & \underset{(\ref{theo:chain_rule_eq})}{\implies}
        \forall \tau \in [0,1], (f \circ g)'(\tau) = \nabla_f(g(\tau)) * (y - x)^T \\
      & \underset{\int_{}^{}}{\implies} f(y) - f(x) = \int_{0}^{1}{\nabla_f(g(\tau)) * (y - x)^T d\tau}
    \end{array}
  \end{equation*}
  \begin{equation*}
    \begin{array}{ll}
      f(y) & = f(x) + \int_{0}^{1}{\nabla_f(g(\tau)) * (y - x)^T d\tau} \\
      & = f(x) + \nabla_f(x) * (y - x)^T + \int_{0}^{1}{(\nabla_f(g(\tau)) - \nabla_f(x)) * (y - x)^T d\tau} \\
      & \underset{Cauchy-Schwarz}{\leq} f(x) + \nabla_f(x) * (y - x)^T + \int_{0}^{1}{\norm{\nabla_f(g(\tau)) - \nabla_f(x)}_m * \norm{y - x}_m d\tau} \\
      & \underset{(\ref{def:lsmooth_eq})}{\leq} f(x) + \nabla_f(x) * (y - x)^T + L * \norm{y - x}_m^2 * \int_{0}^{1}{\tau d\tau}
    \end{array}
  \end{equation*}
\end{proof}

% Co-coercivity for gradient
\begin{proposition}
  {\normalfont
    Let $L \in \Real^{+*}$ and $f \in \mathcal{D}(\Real^m,\Real)$. If $f$ \textit{convex} and \textit{L-smooth} then \begin{equation}\label{prop:grad_cocoercivity}
      \begin{gathered}
        \forall x \in \Real^m, \forall y \in \Real^m, \\
        \frac{1}{L} * \norm{\nabla_f(y) - \nabla_f(x)}_m^2 \leq (\nabla_f(y) - \nabla_f(x)) * (y - x)^T
      \end{gathered}
    \end{equation} \par
    \textbf{Notes:} This proposition is named the gradient co-coercivity.
  }
\end{proposition}

\begin{proof}
  Let $x \in \Real^m$, $y \in \Real^m$ and $z = x - \frac{1}{L}(\nabla_f(y) - \nabla_f(x))$.
  \begin{equation*}
    \begin{array}{ll}
      f(y) - f(x) & = f(y) - f(z) + f(z) - f(x) \\
      & \underset{(\ref{prop:convex_grad}),(\ref{prop:lsmooth_implies})}{\leq} \nabla_f(y) * (y - z)^T + \nabla_f(x) * (z - x) + \frac{L}{2} * \norm{z - x}_m^2 \\
      & \leq \nabla_f(y) * (y - x)^T - \frac{1}{2L} * \norm{\nabla_f(x) - \nabla_f(y)}^2_m
    \end{array}
  \end{equation*} \par
  It means the inequality is true for all $x \in \Real^m$ and $y \in \Real^m$.

  Let $x \in \Real^m$ and $y \in \Real^m$. The previous inequality gives \begin{equation*}
    \begin{array}{lll}
      (a) : & f(y) - f(x) \leq \nabla_f(y) * (y - x)^T - \frac{1}{2L} * \norm{\nabla_f(x) - \nabla_f(y)}^2_m \\
      (b) : & f(x) - f(y) \leq \nabla_f(x) * (x - y)^T - \frac{1}{2L} * \norm{\nabla_f(y) - \nabla_f(x)}^2_m
    \end{array}
  \end{equation*}
  \begin{equation*}
    \underset{(a) + (b)}{\implies} 0 \leq (\nabla_f(y) - \nabla_f(x)) * (y - x)^T - \frac{1}{L} * \norm{\nabla_f(y) - \nabla_f(x)}^2_m
  \end{equation*}
\end{proof}

\subsection{Algorithms}

% Vanilla gradient descent

% Stochastic gradient descent

% SGD with decay and momentum

\section{References}

\end{document}